{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MqJXdKydP2w"
   },
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "Dans ce notebook, nous allons remplacer le LSTM par le transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "MNKbpqYslGAU",
    "outputId": "823b325e-906d-4b1a-bd3e-237a27e746ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /home/amina/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (4.48.2)\n",
      "Requirement already satisfied: requests in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (2.22.0)\n",
      "Requirement already satisfied: torch in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.17.2)\n",
      "Requirement already satisfied: six in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (0.1.91)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2.8)\n",
      "Requirement already satisfied: future in /home/amina/anaconda3/lib/python3.7/site-packages (from torch->torchtext==0.6.0) (0.17.1)\n",
      "Requirement already satisfied: pytorch-crf in /home/amina/anaconda3/lib/python3.7/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!pip install pytorch-crf\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from torchcrf import CRF\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwVsLgt9iH_k"
   },
   "source": [
    "In PyTorch, you can check whether a GPU exists with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "45545BKHmC7l",
    "outputId": "e6b7cd4e-b022-44e5-bef9-27faf2ac11b3"
   },
   "outputs": [],
   "source": [
    "available_gpu = torch.cuda.is_available()\n",
    "if available_gpu:\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    use_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    use_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj6lBUSJmp2K"
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QdrcnlymJYp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-65abbd37263a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(lower = True) \n",
    "TAG = data.Field(unk_token = None) \n",
    "CHAR_NESTING= Field(tokenize=list)\n",
    "CHAR = NestedField(CHAR_NESTING) \n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path=\"data_ner/\",\n",
    "        train=\"train.csv\",\n",
    "        validation=\"valid.csv\",\n",
    "        test=\"test.csv\", format='csv', skip_header=True,\n",
    "        fields=(\n",
    "            ((\"text\", \"char\"), (TEXT, CHAR)), \n",
    "            (\"tag\", TAG)\n",
    "        )\n",
    "    )\n",
    "\n",
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "TAG.build_vocab(train_data)\n",
    "CHAR.build_vocab(train_data) \n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort=False)\n",
    "\n",
    "# padding index\n",
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "CHAR_PAD_IDX = CHAR.vocab.stoi[CHAR.pad_token]  \n",
    "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKP8oaESnWiP"
   },
   "source": [
    "# Construire le modèle\n",
    "\n",
    "Pour le modèle transformer, on ajoute une couche fully-connected avec une activation GELU et une autre couche fully-connected qui transforme la dimension de la sortie en nombre correcte de tags possible pour la couche CRF.\n",
    "\n",
    "Comme nous n'utilisons pas le Transformer complet Encoder-Decoder décrit par [Vaswani et al., 2017](https://arxiv.org/pdf/1706.03762.pdf). Nous n'avons besoin que des encoders, pour \"encoder\" l'information de chaque token et déterminer s'il s'agit d'une entité. \n",
    "On utilise alors les deux modules de PyTorch `TransformerEncoder` and `TransformerEncoderLayer`.\n",
    "\n",
    "De plus, la classe `PositionalEncoding` provient de la page de tutoriels de PyTorch.\n",
    "Elle est mentionnée dans l'article de [Devlin et al., 2019](https://arxiv.org/pdf/1810.04805.pdf), on somme alors les embeddings positionnels au embeddings des tokens (embeddings de mots et de caractère dans notre cas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6brXA7dknKso"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,\n",
    "                 char_input_dim,\n",
    "                 char_cnn_filter_num,\n",
    "                 char_cnn_kernel_size,\n",
    "                 attn_heads,\n",
    "                 fc_hidden,\n",
    "                 trf_layers,\n",
    "                 output_dim,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,\n",
    "                 trf_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,\n",
    "                 char_pad_idx,\n",
    "                 tag_pad_idx):  \n",
    "        super().__init__()\n",
    "        self.char_pad_idx = char_pad_idx\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.tag_pad_idx = tag_pad_idx\n",
    "\n",
    "        # LAYER 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # LAYER 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim \n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "\n",
    "        # LAYER 2: Transformer\n",
    "        all_emb_size = embedding_dim + (char_emb_dim * char_cnn_filter_num)\n",
    "        self.position_encoder = PositionalEncoding(\n",
    "            d_model=all_emb_size\n",
    "        )\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=all_emb_size,\n",
    "            nhead=attn_heads,\n",
    "            activation=\"relu\",\n",
    "            dropout=trf_dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layers,\n",
    "            num_layers=trf_layers\n",
    "        )\n",
    "        \n",
    "        # LAYER 3: 2-couches fully-connected avec GELU activation \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=all_emb_size,\n",
    "            out_features=fc_hidden\n",
    "        )\n",
    "        self.fc1_gelu = nn.GELU()\n",
    "        self.fc1_norm = nn.LayerNorm(fc_hidden)\n",
    "        self.fc2_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=fc_hidden,\n",
    "            out_features=output_dim\n",
    "        )\n",
    "\n",
    "        # LAYER 4: CRF\n",
    "        self.crf = CRF(num_tags=output_dim)\n",
    "        \n",
    "        # init poids distribution normale \n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars, tags=None):\n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # tags = [sentence length, batch size]\n",
    "        \n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "\n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels) \n",
    "        for sent_i in range(sent_len):\n",
    "            \n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]\n",
    "            \n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)\n",
    "            \n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "   \n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2)\n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    " \n",
    "        # Transformer\n",
    "        key_padding_mask = torch.as_tensor(words == self.word_pad_idx).permute(1, 0)\n",
    "        # pos_out = [sentence length, batch size, embedding dim + char emb dim * num filter]\n",
    "        pos_out = self.position_encoder(word_features)\n",
    "        # enc_out = [sentence length, batch size, embedding dim + char emb dim * num filter]\n",
    "        enc_out = self.encoder(pos_out, src_key_padding_mask=key_padding_mask)\n",
    "        # Fully-connected\n",
    "        # fc1_out = [sentence length, batch size, fc hidden]\n",
    "        fc1_out = self.fc1_norm(self.fc1_gelu(self.fc1(enc_out)))\n",
    "        # fc2_out = [sentence length, batch size, output dim]\n",
    "        fc2_out = self.fc2(self.fc2_dropout(fc1_out))\n",
    "\n",
    "        # CRF\n",
    "        crf_mask = words != self.word_pad_idx\n",
    "        crf_out = self.crf.decode(fc2_out, mask=crf_mask)\n",
    "        crf_loss = -self.crf(fc2_out, tags=tags, mask=crf_mask) if tags is not None else None\n",
    "        return crf_out, crf_loss\n",
    "\n",
    "    def init_embeddings(self, pretrained=None, freeze=True):\n",
    "        # initialize embedding for padding as zero\n",
    "        self.embedding.weight.data[self.word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[self.char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=self.word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n",
    "\n",
    "    def init_crf_transitions(self, tag_names, imp_value=-100):\n",
    "        \n",
    "        num_tags = len(tag_names)\n",
    "        for i in range(num_tags):\n",
    "            tag_name = tag_names[i]\n",
    "            \n",
    "            # I et <pad> impossible au début\n",
    "            if tag_name[0] in (\"I\") or tag_name == \"<pad>\":\n",
    "                torch.nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
    "                \n",
    "            # B impossible à la fin\n",
    "            if tag_name[0] in (\"B\"):\n",
    "                torch.nn.init.constant_(self.crf.end_transitions[i], imp_value)\n",
    "                \n",
    "        # init transitions impossible entre positions\n",
    "        tag_is = {}\n",
    "        for tag_position in (\"B\", \"I\", \"O\"):\n",
    "            tag_is[tag_position] = [i for i, tag in enumerate(tag_names) if tag[0] == tag_position]\n",
    "        tag_is[\"P\"] = [i for i, tag in enumerate(tag_names) if tag == \"tag\"]\n",
    "        impossible_transitions_position = {\n",
    "            \"B\": \"BP\",\n",
    "            \"I\": \"BP\",\n",
    "            \"O\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_position.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        torch.nn.init.constant_(\n",
    "                            self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                        )\n",
    "        \n",
    "        # init transitions impossible pour I et B pour des entités de types différents\n",
    "        impossible_transitions_tags = {\n",
    "            \"B\": \"I\",\n",
    "            \"I\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_tags.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        if tag_names[from_tag_i].split(\"-\")[1] != tag_names[to_tag_i].split(\"-\")[1]:\n",
    "                            torch.nn.init.constant_(\n",
    "                                self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                            )\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "FUL7Z0eynp1k",
    "outputId": "24be05dd-9acc-48f6-f333-8474bdc82bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,769,279 trainable parameters.\n",
      "Transformer(\n",
      "  (embedding): Embedding(30050, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (char_emb): Embedding(85, 37, padding_idx=1)\n",
      "  (char_cnn): Conv1d(37, 148, kernel_size=(3,), stride=(1,), groups=37)\n",
      "  (cnn_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (position_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=448, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=448, bias=True)\n",
      "        (norm1): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((448,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=448, out_features=256, bias=True)\n",
      "  (fc1_gelu): GELU()\n",
      "  (fc1_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (fc2_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=22, bias=True)\n",
      "  (crf): CRF(num_tags=22)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    input_dim=len(TEXT.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=37,  \n",
    "    char_input_dim=len(CHAR.vocab),\n",
    "    char_cnn_filter_num=4, \n",
    "    char_cnn_kernel_size=3,\n",
    "    attn_heads=8,  \n",
    "    fc_hidden=256,  \n",
    "    trf_layers=1,\n",
    "    output_dim=len(TAG.vocab),\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    trf_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    tag_pad_idx=TAG_PAD_IDX,\n",
    ")\n",
    "model.init_embeddings(\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    pretrained= TEXT.vocab.vectors,\n",
    "    freeze=True\n",
    ")\n",
    "# CRF transitions initialisation\n",
    "model.init_crf_transitions(\n",
    "    tag_names=TAG.vocab.itos\n",
    ")\n",
    "print(f\"Le modèle a {model.count_parameters():,} paramètres à entraîner.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pu7dqXjJnPxj"
   },
   "source": [
    "La dimension d'entrée des transformer doit être divisible par le nombre de têtes d'attention (`attn_heads`). Comme nous avons deux embeddings, la dimension d'entrée est:\n",
    "`embedding_dim` + `char_emb_dim` * `char_cnn_filter_num` = `emb dim total`\n",
    "\n",
    "= `300` + `37` * `4` = `448`\n",
    "\n",
    "Et 448 est divisible par `attn_heads`= 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLGiZih_nyeL"
   },
   "source": [
    "# Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_loss(preds, y):\n",
    "    index_o = TAG.vocab.stoi[\"O\"]\n",
    "    positive_labels = [i for i in range(len(TAG.vocab.itos))\n",
    "                           if i not in (TAG_PAD_IDX, index_o)]\n",
    "    flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
    "    positive_preds = [pred for pred in flatten_preds\n",
    "                          if pred not in (TAG_PAD_IDX, index_o)]\n",
    "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
    "    \n",
    "    f1 = f1_score(\n",
    "            y_true=flatten_y,\n",
    "            y_pred=flatten_preds,\n",
    "            labels=positive_labels,\n",
    "            average=\"micro\"\n",
    "        ) if len(positive_preds) > 0 else 0\n",
    "    \n",
    "    print(\"f1 : \", f1)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.tag\n",
    "        chars = batch.char \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "        \n",
    "        # pour calculer la loss et l'accuracy, on flatten true tags\n",
    "        true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "            ]\n",
    "        batch_acc = categorical_accuracy(pred_tags_list, true_tags_list)\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.tag\n",
    "            chars = batch.char\n",
    "            \n",
    "            pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "            true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "                ]\n",
    "            batch_acc = categorical_accuracy(pred_tags_list, true_tags_list)\n",
    "   \n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_acc += batch_acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut5-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field, char_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    max_word_len = max([len(token) for token in tokens])\n",
    "    numericalized_chars = []\n",
    "    char_pad_id = char_field.vocab.stoi[CHAR.pad_token] \n",
    "    for token in tokens:\n",
    "        numericalized_chars.append(\n",
    "                [char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "                )\n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]  \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = torch.as_tensor(numericalized_chars)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device) \n",
    "    predictions, _ = model(token_tensor, char_tensor)\n",
    "    print(predictions)\n",
    "    predicted_tags = [tag_field.vocab.itos[t] for t in predictions[0]]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['tag']\n",
    "\n",
    "print(sentence)\n",
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       TAG,\n",
    "                                       CHAR)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xQRKbOpwo96O",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fcd3716d-d256-45e9-fd75-b85d2010ef42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 1036.005 | Trn Acc: 81.66%\n",
      "\tVal Loss: 702.041 | Val Acc: 85.67%\n",
      "Epoch: 02 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 806.966 | Trn Acc: 83.09%\n",
      "\tVal Loss: 663.931 | Val Acc: 85.67%\n",
      "Epoch: 03 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 682.821 | Trn Acc: 82.17%\n",
      "\tVal Loss: 541.896 | Val Acc: 81.61%\n",
      "Epoch: 04 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 584.053 | Trn Acc: 81.50%\n",
      "\tVal Loss: 487.977 | Val Acc: 81.72%\n",
      "Epoch: 05 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 515.918 | Trn Acc: 82.35%\n",
      "\tVal Loss: 443.196 | Val Acc: 82.46%\n",
      "Epoch: 06 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 445.261 | Trn Acc: 84.12%\n",
      "\tVal Loss: 343.260 | Val Acc: 87.55%\n",
      "Epoch: 07 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 393.804 | Trn Acc: 85.59%\n",
      "\tVal Loss: 316.632 | Val Acc: 88.07%\n",
      "Epoch: 08 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 355.255 | Trn Acc: 86.69%\n",
      "\tVal Loss: 283.316 | Val Acc: 89.70%\n",
      "Epoch: 09 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 325.585 | Trn Acc: 87.53%\n",
      "\tVal Loss: 269.109 | Val Acc: 89.86%\n",
      "Epoch: 10 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 306.323 | Trn Acc: 88.17%\n",
      "\tVal Loss: 265.466 | Val Acc: 89.88%\n",
      "Epoch: 11 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 289.435 | Trn Acc: 88.73%\n",
      "\tVal Loss: 272.465 | Val Acc: 89.97%\n",
      "Epoch: 12 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 277.153 | Trn Acc: 89.17%\n",
      "\tVal Loss: 248.797 | Val Acc: 90.57%\n",
      "Epoch: 13 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 268.797 | Trn Acc: 89.51%\n",
      "\tVal Loss: 269.751 | Val Acc: 89.87%\n",
      "Epoch: 14 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 258.506 | Trn Acc: 89.84%\n",
      "\tVal Loss: 261.187 | Val Acc: 89.96%\n",
      "Epoch: 15 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 250.440 | Trn Acc: 90.05%\n",
      "\tVal Loss: 246.677 | Val Acc: 90.83%\n",
      "Epoch: 16 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 242.165 | Trn Acc: 90.25%\n",
      "\tVal Loss: 230.214 | Val Acc: 91.35%\n",
      "Epoch: 17 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 236.970 | Trn Acc: 90.72%\n",
      "\tVal Loss: 254.886 | Val Acc: 91.01%\n",
      "Epoch: 18 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 234.722 | Trn Acc: 90.57%\n",
      "\tVal Loss: 267.156 | Val Acc: 90.10%\n",
      "Epoch: 19 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 229.840 | Trn Acc: 90.73%\n",
      "\tVal Loss: 238.467 | Val Acc: 91.20%\n",
      "Epoch: 20 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 223.032 | Trn Acc: 91.06%\n",
      "\tVal Loss: 238.693 | Val Acc: 91.02%\n",
      "Epoch: 21 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 221.538 | Trn Acc: 91.24%\n",
      "\tVal Loss: 231.600 | Val Acc: 91.11%\n",
      "Epoch: 22 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 214.975 | Trn Acc: 91.53%\n",
      "\tVal Loss: 232.859 | Val Acc: 91.43%\n",
      "Epoch: 23 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 214.524 | Trn Acc: 91.48%\n",
      "\tVal Loss: 242.605 | Val Acc: 90.51%\n",
      "Epoch: 24 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 210.347 | Trn Acc: 91.60%\n",
      "\tVal Loss: 234.175 | Val Acc: 91.41%\n",
      "Epoch: 25 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 214.101 | Trn Acc: 91.59%\n",
      "\tVal Loss: 232.269 | Val Acc: 91.55%\n",
      "Epoch: 26 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 204.555 | Trn Acc: 91.91%\n",
      "\tVal Loss: 247.430 | Val Acc: 90.92%\n",
      "Epoch: 27 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 203.831 | Trn Acc: 91.90%\n",
      "\tVal Loss: 238.864 | Val Acc: 91.53%\n",
      "Epoch: 28 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 201.811 | Trn Acc: 91.95%\n",
      "\tVal Loss: 221.672 | Val Acc: 92.27%\n",
      "Epoch: 29 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 199.062 | Trn Acc: 92.20%\n",
      "\tVal Loss: 232.189 | Val Acc: 91.21%\n",
      "Epoch: 30 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 196.352 | Trn Acc: 92.34%\n",
      "\tVal Loss: 236.945 | Val Acc: 91.44%\n",
      "Epoch: 31 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 191.794 | Trn Acc: 92.35%\n",
      "\tVal Loss: 218.375 | Val Acc: 91.91%\n",
      "Epoch: 32 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 192.210 | Trn Acc: 92.36%\n",
      "\tVal Loss: 225.242 | Val Acc: 91.76%\n",
      "Epoch: 33 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 189.669 | Trn Acc: 92.71%\n",
      "\tVal Loss: 246.221 | Val Acc: 91.14%\n",
      "Epoch: 34 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 189.650 | Trn Acc: 92.49%\n",
      "\tVal Loss: 238.123 | Val Acc: 91.99%\n",
      "Epoch: 35 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 183.596 | Trn Acc: 92.80%\n",
      "\tVal Loss: 240.504 | Val Acc: 91.07%\n",
      "Epoch: 36 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 182.580 | Trn Acc: 92.83%\n",
      "\tVal Loss: 220.278 | Val Acc: 91.60%\n",
      "Epoch: 37 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 182.195 | Trn Acc: 92.79%\n",
      "\tVal Loss: 232.870 | Val Acc: 91.66%\n",
      "Epoch: 38 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 184.952 | Trn Acc: 92.62%\n",
      "\tVal Loss: 217.108 | Val Acc: 92.02%\n",
      "Epoch: 39 | Epoch Time: 0m 12s\n",
      "\tTrn Loss: 183.375 | Trn Acc: 92.61%\n",
      "\tVal Loss: 233.844 | Val Acc: 91.76%\n",
      "Epoch: 40 | Epoch Time: 0m 13s\n",
      "\tTrn Loss: 179.359 | Trn Acc: 92.94%\n",
      "\tVal Loss: 228.368 | Val Acc: 91.81%\n",
      "Test Loss: 271.595 |  Test Acc: 91.32%\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The will deliver a speech about the conflict in Sao Paulo at tomorrow in Anne Mary with Jack.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                  TAG,\n",
    "                                  CHAR)\n",
    "\n",
    "print(unks)\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vj6lBUSJmp2K"
   ],
   "name": "6 - Transformer Model for Indonesian NER with PyTorch on GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
