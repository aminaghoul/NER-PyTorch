{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7MqJXdKydP2w"
   },
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "Dans ce notebook, nous allons remplacer le LSTM par le transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "MNKbpqYslGAU",
    "outputId": "823b325e-906d-4b1a-bd3e-237a27e746ab"
   },
   "outputs": [],
   "source": [
    "#!pip install torchtext==0.6.0\n",
    "#!pip install pytorch-crf\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from torchcrf import CRF\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "from torchcrf import CRF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj6lBUSJmp2K"
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QdrcnlymJYp"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(lower = True) \n",
    "TAG = data.Field(unk_token = None) \n",
    "CHAR_NESTING= Field(tokenize=list)\n",
    "CHAR = NestedField(CHAR_NESTING) \n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path=\"data_ner/\",\n",
    "        train=\"train.csv\",\n",
    "        validation=\"valid.csv\",\n",
    "        test=\"test.csv\", format='csv', skip_header=True,\n",
    "        fields=(\n",
    "            ((\"text\", \"char\"), (TEXT, CHAR)), \n",
    "            (\"tag\", TAG)\n",
    "        )\n",
    "    )\n",
    "\n",
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
    "                 vectors = \"glove.6B.300d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "TAG.build_vocab(train_data)\n",
    "CHAR.build_vocab(train_data) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort=False)\n",
    "\n",
    "# padding index\n",
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "CHAR_PAD_IDX = CHAR.vocab.stoi[CHAR.pad_token]  \n",
    "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKP8oaESnWiP"
   },
   "source": [
    "# Construire le modèle\n",
    "\n",
    "Pour le modèle transformer, on ajoute une couche fully-connected avec une activation GELU et une autre couche fully-connected qui transforme la dimension de la sortie en nombre correcte de tags possible pour la couche CRF.\n",
    "\n",
    "Comme nous n'utilisons pas le Transformer complet Encoder-Decoder décrit par [Vaswani et al., 2017](https://arxiv.org/pdf/1706.03762.pdf). Nous n'avons besoin que des encoders, pour \"encoder\" l'information de chaque token et déterminer s'il s'agit d'une entité. \n",
    "On utilise alors les deux modules de PyTorch `TransformerEncoder` and `TransformerEncoderLayer`.\n",
    "\n",
    "De plus, la classe `PositionalEncoding` provient de la page de tutoriels de PyTorch.\n",
    "Elle est mentionnée dans l'article de [Devlin et al., 2019](https://arxiv.org/pdf/1810.04805.pdf), on somme alors les embeddings positionnels au embeddings des tokens (embeddings de mots et de caractère dans notre cas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6brXA7dknKso"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,\n",
    "                 char_input_dim,\n",
    "                 char_cnn_filter_num,\n",
    "                 char_cnn_kernel_size,\n",
    "                 attn_heads,\n",
    "                 fc_hidden,\n",
    "                 trf_layers,\n",
    "                 output_dim,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,\n",
    "                 trf_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,\n",
    "                 char_pad_idx,\n",
    "                 tag_pad_idx):  \n",
    "        super().__init__()\n",
    "        self.char_pad_idx = char_pad_idx\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.tag_pad_idx = tag_pad_idx\n",
    "\n",
    "        # LAYER 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim= embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # LAYER 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim \n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "\n",
    "        # LAYER 2: Transformer\n",
    "        all_emb_size = embedding_dim + (char_emb_dim * char_cnn_filter_num) \n",
    "        self.position_encoder = PositionalEncoding(\n",
    "            d_model=all_emb_size\n",
    "        )\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=all_emb_size,\n",
    "            nhead=attn_heads,\n",
    "            activation=\"relu\",\n",
    "            dropout=trf_dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layers,\n",
    "            num_layers=trf_layers\n",
    "        )\n",
    "        \n",
    "        # LAYER 3: 2-couches fully-connected avec GELU activation \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=all_emb_size,\n",
    "            out_features=fc_hidden\n",
    "        )\n",
    "        self.fc1_gelu = nn.GELU()\n",
    "        self.fc1_norm = nn.LayerNorm(fc_hidden)\n",
    "        self.fc2_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=fc_hidden,\n",
    "            out_features=output_dim\n",
    "        )\n",
    "\n",
    "        # LAYER 4: CRF\n",
    "        self.crf = CRF(num_tags=output_dim)\n",
    "        \n",
    "        # init poids distribution normale \n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars, tags=None):\n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # tags = [sentence length, batch size]\n",
    "\n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels) \n",
    "        for sent_i in range(sent_len):\n",
    "            \n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]\n",
    "            \n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)\n",
    "            \n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "   \n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2).to(device)\n",
    "        \n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    "        # Transformer\n",
    "        key_padding_mask = torch.as_tensor(words == self.word_pad_idx).permute(1, 0)\n",
    "        \n",
    "        # pos_out = [sentence length, batch size, embedding dim + char emb dim * num filter]\n",
    "        pos_out = self.position_encoder(word_features)\n",
    "        # enc_out = [sentence length, batch size, embedding dim + char emb dim * num filter]\n",
    "        enc_out = self.encoder(pos_out, src_key_padding_mask=key_padding_mask)\n",
    "        # Fully-connected\n",
    "        # fc1_out = [sentence length, batch size, fc hidden]\n",
    "        fc1_out = self.fc1_norm(self.fc1_gelu(self.fc1(enc_out)))\n",
    "        # fc2_out = [sentence length, batch size, output dim]\n",
    "        fc2_out = self.fc2(self.fc2_dropout(fc1_out))\n",
    "     \n",
    "        # CRF    \n",
    "        crf_mask = words != self.word_pad_idx\n",
    "        crf_out = self.crf.decode(fc2_out, mask=crf_mask)\n",
    "        crf_loss = -self.crf(fc2_out, tags=tags, mask=crf_mask) if tags is not None else None\n",
    "        return crf_out, crf_loss\n",
    "        \n",
    "    def init_embeddings(self, char_pad_idx, word_pad_idx, pretrained=None, freeze=True):\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n",
    "    \n",
    "    def init_crf_transitions(self, tag_names, imp_value=-100):\n",
    "        num_tags = len(tag_names)\n",
    "        for i in range(num_tags):\n",
    "            tag_name = tag_names[i]\n",
    "            # I and <pad> impossible as a start\n",
    "            if tag_name[0] == \"I\" or tag_name[0] == \"<pad>\":\n",
    "                torch.nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
    "        # init impossible transitions between positions\n",
    "        tag_is = {}\n",
    "        for tag_position in (\"B\", \"I\", \"O\"):\n",
    "            tag_is[tag_position] = [i for i, tag in enumerate(tag_names) if tag[0] == tag_position]\n",
    "        impossible_transitions_position = {\n",
    "            \"O\": \"I\"\n",
    "\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_position.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            \n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                    \n",
    "                        torch.nn.init.constant_(\n",
    "                            self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                        )\n",
    "        # init impossible B and I transitions to different entity types\n",
    "        impossible_transitions_tags = {\n",
    "            \"B\": \"I\",\n",
    "            \"I\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_tags.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        if tag_names[from_tag_i].split(\"-\")[1] != tag_names[to_tag_i].split(\"-\")[1]:\n",
    "                            torch.nn.init.constant_(\n",
    "                                self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                            )\n",
    "\n",
    "        \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "FUL7Z0eynp1k",
    "outputId": "24be05dd-9acc-48f6-f333-8474bdc82bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 22,339,840 paramètres à entraîner.\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    input_dim=len(TEXT.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=53,  \n",
    "    char_input_dim=len(CHAR.vocab),\n",
    "    char_cnn_filter_num=4, \n",
    "    char_cnn_kernel_size=3,\n",
    "    attn_heads=8,  \n",
    "    fc_hidden=256,  \n",
    "    trf_layers=6,\n",
    "    output_dim=len(TAG.vocab),\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    trf_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    tag_pad_idx=TAG_PAD_IDX,\n",
    ")\n",
    "model.init_embeddings(\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    #pretrained= TEXT.vocab.vectors,\n",
    "    #freeze=True\n",
    ")\n",
    "# CRF transitions initialisation\n",
    "model.init_crf_transitions(\n",
    "    tag_names=TAG.vocab.itos\n",
    ")\n",
    "print(f\"Le modèle a {model.count_parameters():,} paramètres à entraîner.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pu7dqXjJnPxj"
   },
   "source": [
    "La dimension d'entrée des transformer doit être divisible par le nombre de têtes d'attention (`attn_heads`). Comme nous avons deux embeddings, la dimension d'entrée est:\n",
    "`embedding_dim` + `char_emb_dim` * `char_cnn_filter_num` = `emb dim total`\n",
    "\n",
    "= `300` + `37` * `4` = `448`\n",
    "\n",
    "Et 448 est divisible par `attn_heads`= 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLGiZih_nyeL"
   },
   "source": [
    "# Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_loss(preds, y, tag_pad_idx):\n",
    "    index_o = TAG.vocab.stoi[\"O\"]\n",
    "    positive_labels = [i for i in range(len(TAG.vocab.itos))\n",
    "                           if i not in (tag_pad_idx, index_o)]\n",
    "    flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
    "    positive_preds = [pred for pred in flatten_preds\n",
    "                          if pred not in (tag_pad_idx, index_o)]\n",
    "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
    "    \n",
    "    f1 = f1_score(\n",
    "            y_true=flatten_y,\n",
    "            y_pred=flatten_preds,\n",
    "            labels=positive_labels,\n",
    "            average=\"micro\"\n",
    "        ) if len(positive_preds) > 0 else 0\n",
    "       \n",
    "    return f1\n",
    "\n",
    "def accuracy_per_tag(predictions, tags):\n",
    "    n_tags = len(TAG.vocab)\n",
    "    class_correct = list(0 for i in range(n_tags))\n",
    "    class_total = list(0 for i in range(n_tags))\n",
    "    acc = list(0 for i in range(n_tags))\n",
    "    \n",
    "    flatten_preds = [pred for sent_pred in predictions for pred in sent_pred]\n",
    "\n",
    "    flatten_y = [tag for sent_tag in tags for tag in sent_tag]\n",
    "\n",
    "    # # compare predictions to true label\n",
    "    correct = [pred == tag for pred, tag in zip(flatten_preds, flatten_y)]\n",
    "\n",
    "    # # calculate test accuracy for each object class\n",
    "    for i in range(len(flatten_y)):\n",
    "        label = flatten_y[i]\n",
    "        class_correct[label] += correct[i]\n",
    "        class_total[label] += 1\n",
    "    for i in range(n_tags):\n",
    "        if np.sum(class_total[i]) == 0 and np.sum(class_correct[i]) == 0:\n",
    "            res = 100\n",
    "        else:\n",
    "            res = 100 * class_correct[i] / class_total[i]\n",
    "        acc[i] = res, np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        \n",
    "    return acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 19s\n",
      "\tTrain Loss: 245.025 | Train F1 score: 0.00%\n",
      "\t Val. Loss: 265.067 |  Val. F1 score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.tag\n",
    "        chars = batch.char \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "        \n",
    "        # pour calculer la loss et l'accuracy, on flatten true tags\n",
    "        true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "            ]\n",
    "\n",
    "        f1 = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx)\n",
    "        acc = accuracy_per_tag(pred_tags_list, true_tags_list)               \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), acc, epoch_f1 / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.tag\n",
    "            chars = batch.char\n",
    "            \n",
    "            pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "            true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "                ]\n",
    "            \n",
    "            f1 = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx)\n",
    "            acc = accuracy_per_tag(pred_tags_list, true_tags_list) \n",
    "            \n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), acc, epoch_f1 / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_f1 = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut5-model.pt')\n",
    "    if epoch%10 == 0:\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train F1 score: {train_f1*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1 score: {valid_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tags = len(TAG.vocab)\n",
    "for i in range(n_tags):   \n",
    "    print('Train Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], train_acc[i][0],\n",
    "           train_acc[i][1], train_acc[i][2]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_tags):\n",
    "    print('Valid Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], valid_acc[i][0],\n",
    "           valid_acc[i][1], valid_acc[i][2]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut5-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "n_tags = len(TAG.vocab)\n",
    "for i in range(n_tags):   \n",
    "    print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], test_acc[i][0],\n",
    "           test_acc[i][1], test_acc[i][2]))\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test F1 score: {test_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field, char_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    max_word_len = max([len(token) for token in tokens])\n",
    "    numericalized_chars = []\n",
    "    char_pad_id = char_field.vocab.stoi[CHAR.pad_token] \n",
    "    for token in tokens:\n",
    "        numericalized_chars.append(\n",
    "                [char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "                )\n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]  \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = torch.as_tensor(numericalized_chars)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device) \n",
    "    predictions, _ = model(token_tensor, char_tensor)\n",
    "    print(predictions)\n",
    "    predicted_tags = [tag_field.vocab.itos[t] for t in predictions[0]]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['tag']\n",
    "\n",
    "print(sentence)\n",
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       TAG,\n",
    "                                       CHAR)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xQRKbOpwo96O",
    "outputId": "fcd3716d-d256-45e9-fd75-b85d2010ef42"
   },
   "outputs": [],
   "source": [
    "sentence = 'The will deliver a speech about the conflict in Sao Paulo at tomorrow in Anne Mary with Jack.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                  TAG,\n",
    "                                  CHAR)\n",
    "\n",
    "print(unks)\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vj6lBUSJmp2K"
   ],
   "name": "6 - Transformer Model for Indonesian NER with PyTorch on GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
