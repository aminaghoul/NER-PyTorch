{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRC5Mk7DS7il"
   },
   "source": [
    "# BiLSTM et CRF\n",
    "\n",
    "Dans ce notebook nous nous utilisons les champs aléatoires conditionnels (conditional random fields ou CRFs) qui sont généralement utilisés pour le named entityy recognition dans le but de prédire des séquences valides.\n",
    "Par exemple, on ne devrait pas avoir de `B-PER` suivi directement par un autre `B-PER`.\n",
    "\n",
    "Jusqu'à présent, noous avons supposé que les tags entre eux étaient indépendants. Lors de labelisage de séquence, cette hypothèse est inexacte. En effet, si nous savons que la probabilité que le mot précédent soit «I-LOC» est élevée, alors le mot actuel est moins susceptible de faire partie de la même entité («I-LOC»). CRF, par essence, tente de prédire la séquence la plus probable. Si vous voulez en savoir plus sur le CRF, en particulier dans le domaine de la classification des séquences, [cette série de vidéos](https://youtu.be/GF3iSJkgPbA) par Hugo Larochelle est très bien. Pour l'implémentation CRF, on utilisera le package [pytorch-crf](https://github.com/kmkurn/pytorch-crf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VOsFMtA8IWOc",
    "outputId": "89146cdc-7edf-4b6c-ce7b-72b61a8774fe"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/gdrive\")\n",
    "\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "s7pqLoSXKbh6",
    "outputId": "0ca5ebdf-b819-4a70-9098-978868d85385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /opt/conda/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (4.46.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (1.14.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from torchtext==0.6.0) (0.1.91)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2020.6.20)\n",
      "Requirement already satisfied: pytorch-crf in /opt/conda/lib/python3.7/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!pip install pytorch-crf\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "from torchcrf import CRF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4LF_qyLKvfK"
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JAamZSXiKnJl"
   },
   "outputs": [],
   "source": [
    "# pour la reproductibilité\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(lower = True) \n",
    "TAG = data.Field(unk_token = None) # les tags sont tous connus on a alors unk_token = None\n",
    "CHAR_NESTING= Field(tokenize=list)\n",
    "CHAR = NestedField(CHAR_NESTING) \n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path=\"data_ner/\",\n",
    "        train=\"train.csv\",\n",
    "        validation=\"valid.csv\",\n",
    "        test=\"test.csv\", format='csv', skip_header=True,\n",
    "        fields=(\n",
    "            ((\"text\", \"char\"), (TEXT, CHAR)), \n",
    "            (\"tag\", TAG)\n",
    "        )\n",
    "    )\n",
    "\n",
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
    "                 vectors = \"glove.6B.300d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "TAG.build_vocab(train_data)\n",
    "CHAR.build_vocab(train_data) \n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort=False)\n",
    "\n",
    "# padding index\n",
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "CHAR_PAD_IDX = CHAR.vocab.stoi[CHAR.pad_token]  \n",
    "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXY-SyrWKx4u"
   },
   "source": [
    "# Construire le modèle\n",
    "\n",
    "Pour la classe de modèle, il existe trois mises à jour principales:\n",
    "\n",
    "1. préparez la couche CRF lors de l'initialisation. Nous devons spécifier le nombre de tags possibles dans le text.\n",
    "2. inclure la logique de la couche CRF dans la séquence `forward ()`. Il y a un changement majeur dans le `forward ()` en raison de l'implémentation du package `pytorch-crf`. Jusqu'à présent, nous effectuons séparément la propagation forward et le calcul des pertes. Désormais, le calcul des pertes est intégré à la propagation forward.\n",
    "3. initialisez toutes les transitions impossibles avec un nombre vraiment bas (-100) dans la fonction `init_crf_transitions`. C'est là que nous imposons la logique de séquence BIO au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PW8shLquKyr-"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,\n",
    "                 char_input_dim,\n",
    "                 char_cnn_filter_num,\n",
    "                 char_cnn_kernel_size,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 lstm_layers,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,\n",
    "                 lstm_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,\n",
    "                 char_pad_idx,\n",
    "                 tag_pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        # LAYER 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # LAYER 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim  # different 1d conv for each embedding dim\n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "        \n",
    "        # LAYER 2: BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim + (char_emb_dim * char_cnn_filter_num),\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # LAYER 3: Fully-connected  \n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  \n",
    "        # LAYER 4: CRF\n",
    "\n",
    "        self.tag_pad_idx = tag_pad_idx\n",
    "        self.crf = CRF(num_tags=output_dim)\n",
    "        \n",
    "        # init poids avec distribution normale \n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars, tags=None):\n",
    "\n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # tags = [sentence length, batch size]\n",
    "        \n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "    \n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        \n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels)\n",
    "        for sent_i in range(sent_len):\n",
    "            \n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]\n",
    "            \n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)\n",
    "            \n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "        \n",
    "        \n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2).to(device)\n",
    "        \n",
    "        # concat word et char embedding\n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    "        \n",
    "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
    "        lstm_out, _ = self.lstm(word_features)\n",
    "        \n",
    "        # fc_out = [sentence length, batch size, output dim]\n",
    "        fc_out = self.fc(self.fc_dropout(lstm_out))\n",
    "        if tags is not None:\n",
    "            mask = tags != self.tag_pad_idx\n",
    "            crf_out = self.crf.decode(fc_out, mask=mask)\n",
    "            crf_loss = -self.crf(fc_out, tags=tags, mask=mask) if tags is not None else None\n",
    "        else:\n",
    "            crf_out = self.crf.decode(fc_out)\n",
    "            crf_loss = None\n",
    "          \n",
    "        return crf_out , crf_loss\n",
    "\n",
    "    def init_embeddings(self, char_pad_idx, word_pad_idx, pretrained=None, freeze=True):\n",
    "     \n",
    "        # init embedding pad à zéro\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n",
    "\n",
    "   \n",
    "    ### BEGIN MODIFIED SECTION: CRF OUTPUT ###\n",
    "    def init_crf_transitions(self, tag_names, imp_value=-100):\n",
    "        num_tags = len(tag_names)\n",
    "        for i in range(num_tags):\n",
    "            tag_name = tag_names[i]\n",
    "            # I and <pad> impossible as a start\n",
    "            if tag_name[0] == \"I\" or tag_name == \"<pad>\":\n",
    "                torch.nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
    "        # init impossible transitions between positions\n",
    "        tag_is = {}\n",
    "        for tag_position in (\"B\", \"I\", \"O\"):\n",
    "            tag_is[tag_position] = [i for i, tag in enumerate(tag_names) if tag[0] == tag_position]\n",
    "        impossible_transitions_position = {\n",
    "            \"O\": \"I\"\n",
    "\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_position.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            \n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                    \n",
    "                        torch.nn.init.constant_(\n",
    "                            self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                        )\n",
    "        # init impossible B and I transitions to different entity types\n",
    "        impossible_transitions_tags = {\n",
    "            \"B\": \"I\",\n",
    "            \"I\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_tags.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        if tag_names[from_tag_i].split(\"-\")[1] != tag_names[to_tag_i].split(\"-\")[1]:\n",
    "                            torch.nn.init.constant_(\n",
    "                                self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                            )\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "Zb03iYctNAUM",
    "outputId": "4be1d224-4f2d-4a36-b9ce-128b3ce019a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 351,583 paramètres à entraîner.\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(\n",
    "    input_dim=len(TEXT.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(CHAR.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=2,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(TAG.vocab),\n",
    "    lstm_layers=3,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    tag_pad_idx=TAG_PAD_IDX\n",
    ")\n",
    "model.init_embeddings(\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    pretrained= TEXT.vocab.vectors\n",
    "    ,freeze=True\n",
    ")\n",
    "# CRF transitions initialisation\n",
    "model.init_crf_transitions(\n",
    "    tag_names=TAG.vocab.itos\n",
    ")\n",
    "print(f\"Le modèle a {model.count_parameters():,} paramètres à entraîner.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGsjeyHlyWhx"
   },
   "source": [
    "Nous pouvons accéder à la matrice de transition et nous assurer que l'initialisation est effectuée comme prévu :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Wfe5T7dlrS2j",
    "outputId": "084157b9-5a3c-40d0-c506-4a89d50c913f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start and end tag transitions:\n",
      "TAG   \tSTART\tEND\n",
      "<pad> \t-100.0\t-0.0\n",
      "O     \t0.01\t-0.03\n",
      "B-LOC \t0.06\t0.11\n",
      "B-PER \t-0.06\t-0.06\n",
      "B-ORG \t-0.12\t0.07\n",
      "I-PER \t-100.0\t0.0\n",
      "I-ORG \t-100.0\t0.06\n",
      "B-MISC\t-0.15\t-0.15\n",
      "I-LOC \t-100.0\t-0.1\n",
      "I-MISC\t-100.0\t0.13\n",
      "\n",
      "Between tags transitions:\n",
      "   TO\tO    \tB-PER\tI-PER\n",
      "FROM\n",
      "O    \t-0.04\t-0.03\t-100.0\n",
      "B-PER\t0.02 \t0.07 \t-0.08\n",
      "I-PER\t0.0  \t0.14 \t-0.01\n"
     ]
    }
   ],
   "source": [
    "def print_crf_transitions(c, m):\n",
    "    tags = TAG.vocab.itos\n",
    "    max_len_tag = max([len(tag) for tag in tags])\n",
    "    print(\"Start and end tag transitions:\")\n",
    "    print(f\"{'TAG'.ljust(max_len_tag)}\\tSTART\\tEND\")\n",
    "    for tag, start_prob, end_prob in zip(tags, m.crf.start_transitions.tolist(), m.crf.end_transitions.tolist()):\n",
    "        print(f\"{tag.ljust(max_len_tag)}\\t{round(start_prob, 2)}\\t{round(end_prob, 2)}\")\n",
    "    print()\n",
    "    print(\"Between tags transitions:\")\n",
    "    persons_i = [i for i, tag in enumerate(TAG.vocab.itos) if \"PER\" in tag or tag == \"O\"]\n",
    "    max_len_tag = max([len(tag) for tag in TAG.vocab.itos if \"PER\" in tag ])\n",
    "    transitions = m.crf.transitions\n",
    "    to_tags = \"TO\".rjust(max_len_tag) + \"\\t\" + \"\\t\".join([tag.ljust(max_len_tag) for tag in tags if \"PER\" in tag or tag == \"O\"])\n",
    "    print(to_tags)\n",
    "    print(\"FROM\")\n",
    "    for from_tag_i, from_tag_probs in enumerate(transitions[persons_i]):\n",
    "        to_tag_str = f\"{tags[persons_i[from_tag_i]].ljust(max_len_tag)}\"\n",
    "        for to_tag_prob in from_tag_probs[persons_i]:\n",
    "            to_tag_str += f\"\\t{str(round(to_tag_prob.item(), 2)).ljust(max_len_tag)}\"\n",
    "        print(to_tag_str)\n",
    "\n",
    "print_crf_transitions(TEXT, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lWbTw3yMiyr"
   },
   "source": [
    "# Entraînement\n",
    "\n",
    "Les sorties du modèle sont deux listes : les prédictions et les pertes.\n",
    "On prend en considération ces changements en modifiant la fonction qui calcule l'accuracy.\n",
    "\n",
    " - Optimiseur et fonction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1_loss(preds, y, tag_pad_idx):\n",
    "    index_o = TAG.vocab.stoi[\"O\"]\n",
    "    positive_labels = [i for i in range(len(TAG.vocab.itos))\n",
    "                           if i not in (tag_pad_idx, index_o)]\n",
    "    flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
    "    positive_preds = [pred for pred in flatten_preds\n",
    "                          if pred not in (tag_pad_idx, index_o)]\n",
    "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
    "    \n",
    "    f1 = f1_score(\n",
    "            y_true=flatten_y,\n",
    "            y_pred=flatten_preds,\n",
    "            labels=positive_labels,\n",
    "            average=\"micro\"\n",
    "        ) if len(positive_preds) > 0 else 0\n",
    "       \n",
    "    return f1\n",
    "\n",
    "def accuracy_per_tag(predictions, tags):\n",
    "    n_tags = len(TAG.vocab)\n",
    "    class_correct = list(0 for i in range(n_tags))\n",
    "    class_total = list(0 for i in range(n_tags))\n",
    "    acc = list(0 for i in range(n_tags))\n",
    "    \n",
    "    flatten_preds = [pred for sent_pred in predictions for pred in sent_pred]\n",
    "\n",
    "    flatten_y = [tag for sent_tag in tags for tag in sent_tag]\n",
    "\n",
    "    # # compare predictions to true label\n",
    "    correct = [pred == tag for pred, tag in zip(flatten_preds, flatten_y)]\n",
    "\n",
    "    # # calculate test accuracy for each object class\n",
    "    for i in range(len(flatten_y)):\n",
    "        label = flatten_y[i]\n",
    "        class_correct[label] += correct[i]\n",
    "        class_total[label] += 1\n",
    "    for i in range(n_tags):\n",
    "        if np.sum(class_total[i]) == 0 and np.sum(class_correct[i]) == 0:\n",
    "            res = 100\n",
    "        else:\n",
    "            res = 100 * class_correct[i] / class_total[i]\n",
    "        acc[i] = res, np.sum(class_correct[i]), np.sum(class_total[i])\n",
    "        \n",
    "    return acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 4s\n",
      "\tTrain Loss: 1012.668 | Train F1 score: 6.73%\n",
      "\t Val. Loss: 622.206 | Val. F1 score: 31.95%\n",
      "Epoch: 06 | Epoch Time: 0m 57s\n",
      "\tTrain Loss: 146.290 | Train F1 score: 82.95%\n",
      "\t Val. Loss: 125.085 | Val. F1 score: 83.14%\n",
      "Epoch: 11 | Epoch Time: 1m 1s\n",
      "\tTrain Loss: 99.817 | Train F1 score: 87.85%\n",
      "\t Val. Loss: 91.937 | Val. F1 score: 89.02%\n",
      "Epoch: 16 | Epoch Time: 1m 45s\n",
      "\tTrain Loss: 80.490 | Train F1 score: 90.06%\n",
      "\t Val. Loss: 83.835 | Val. F1 score: 89.71%\n",
      "Epoch: 21 | Epoch Time: 3m 5s\n",
      "\tTrain Loss: 67.804 | Train F1 score: 91.42%\n",
      "\t Val. Loss: 84.122 | Val. F1 score: 89.24%\n",
      "Epoch: 26 | Epoch Time: 3m 6s\n",
      "\tTrain Loss: 61.484 | Train F1 score: 92.27%\n",
      "\t Val. Loss: 80.855 | Val. F1 score: 90.04%\n"
     ]
    }
   ],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.tag\n",
    "        chars = batch.char \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "        \n",
    "        # pour calculer la loss et le score f1, on flatten true tags\n",
    "        true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "            ]\n",
    "        f1 = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx)\n",
    "\n",
    "        acc = accuracy_per_tag(pred_tags_list, true_tags_list)\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), acc, epoch_f1 / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.tag\n",
    "            chars = batch.char\n",
    "            \n",
    "            pred_tags_list, batch_loss = model(text, chars, tags)\n",
    "            true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "                ]\n",
    "            \n",
    "            f1 = f1_loss(pred_tags_list, true_tags_list, tag_pad_idx)\n",
    "            acc = accuracy_per_tag(pred_tags_list, true_tags_list)   \n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(iterator), acc, epoch_f1 / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_f1 = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    if epoch%10 == 0:\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train F1 score: {train_f1*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} | Val. F1 score: {valid_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of <pad>: 100% ( 0/ 0)\n",
      "Train Accuracy of     O: 99% (1433/1439)\n",
      "Train Accuracy of B-LOC: 94% (51/54)\n",
      "Train Accuracy of B-PER: 100% (54/54)\n",
      "Train Accuracy of B-ORG: 94% (55/58)\n",
      "Train Accuracy of I-PER: 100% (32/32)\n",
      "Train Accuracy of I-ORG: 100% (31/31)\n",
      "Train Accuracy of B-MISC: 89% (26/29)\n",
      "Train Accuracy of I-LOC: 100% (12/12)\n",
      "Train Accuracy of I-MISC: 77% ( 7/ 9)\n"
     ]
    }
   ],
   "source": [
    "n_tags = len(TAG.vocab)\n",
    "for i in range(n_tags):   \n",
    "    print('Train Accuracy de %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], train_acc[i][0],\n",
    "           train_acc[i][1], train_acc[i][2]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Accuracy of <pad>: 100% ( 0/ 0)\n",
      "Valid Accuracy of     O: 100% (148/148)\n",
      "Valid Accuracy of B-LOC: 100% ( 1/ 1)\n",
      "Valid Accuracy of B-PER: 100% ( 2/ 2)\n",
      "Valid Accuracy of B-ORG: 71% ( 5/ 7)\n",
      "Valid Accuracy of I-PER: 100% ( 2/ 2)\n",
      "Valid Accuracy of I-ORG: 60% ( 3/ 5)\n",
      "Valid Accuracy of B-MISC: 100% ( 1/ 1)\n",
      "Valid Accuracy of I-LOC: 100% ( 0/ 0)\n",
      "Valid Accuracy of I-MISC: 100% ( 0/ 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_tags):\n",
    "    print('Valid Accuracy de %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], valid_acc[i][0],\n",
    "           valid_acc[i][1], valid_acc[i][2]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of <pad>: 100% ( 0/ 0)\n",
      "Test Accuracy of     O: 99% (909/918)\n",
      "Test Accuracy of B-LOC: 79% (27/34)\n",
      "Test Accuracy of B-PER: 66% (24/36)\n",
      "Test Accuracy of B-ORG: 85% (68/80)\n",
      "Test Accuracy of I-PER: 100% (14/14)\n",
      "Test Accuracy of I-ORG: 75% (22/29)\n",
      "Test Accuracy of B-MISC: 85% (18/21)\n",
      "Test Accuracy of I-LOC: 87% ( 7/ 8)\n",
      "Test Accuracy of I-MISC: 100% ( 2/ 2)\n",
      "Test Loss: 130.054 |  Test F1 score: 85.73%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "n_tags = len(TAG.vocab)\n",
    "for i in range(n_tags):   \n",
    "    print('Test Accuracy de %5s: %2d%% (%2d/%2d)' % (\n",
    "           TAG.vocab.itos[i], test_acc[i][0],\n",
    "           test_acc[i][1], test_acc[i][2]))\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test F1 score: {test_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field, char_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    max_word_len = max([len(token) for token in tokens])\n",
    "    numericalized_chars = []\n",
    "    char_pad_id = char_field.vocab.stoi[CHAR.pad_token] \n",
    "    for token in tokens:\n",
    "        numericalized_chars.append(\n",
    "                [char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "                )\n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]  \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.as_tensor(numericalized_tokens)    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = torch.as_tensor(numericalized_chars)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device) \n",
    "    predictions, _ = model(token_tensor, char_tensor)\n",
    "    print(predictions)\n",
    "    predicted_tags = [tag_field.vocab.itos[t] for t in predictions[0]]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b361efe8ed74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                        \u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                        \u001b[0mTAG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                        CHAR)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e3e290469220>\u001b[0m in \u001b[0;36mtag_sentence\u001b[0;34m(model, device, sentence, text_field, tag_field, char_field)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mchar_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericalized_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mchar_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpredicted_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-fd3df68a9c9c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, chars, tags)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# embedding_out = [sentence length, batch size, embedding dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0membedding_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# char_emb_out = [batch size, sentence length, word length, char emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(valid_data.examples[example_index])['text']\n",
    "actual_tags = vars(valid_data.examples[example_index])['tag']\n",
    "\n",
    "print(sentence)\n",
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       TAG,\n",
    "                                       CHAR)\n",
    "\n",
    "print(unks)\n",
    "print(pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "O\t\tO\t\t✔\t\tcricket\n",
      "O\t\tO\t\t✔\t\t-\n",
      "O\t\tB-ORG\t\t✘\t\tleicestershire\n",
      "O\t\tO\t\t✔\t\ttake\n",
      "O\t\tO\t\t✔\t\tover\n",
      "O\t\tO\t\t✔\t\tat\n",
      "O\t\tO\t\t✔\t\ttop\n",
      "O\t\tO\t\t✔\t\tafter\n",
      "O\t\tO\t\t✔\t\tinnings\n",
      "O\t\tO\t\t✔\t\tvictory\n",
      "O\t\tO\t\t✔\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-534c6269478d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   \u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                   \u001b[0mTAG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                   CHAR)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e3e290469220>\u001b[0m in \u001b[0;36mtag_sentence\u001b[0;34m(model, device, sentence, text_field, tag_field, char_field)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mchar_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericalized_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mchar_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpredicted_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-fd3df68a9c9c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, chars, tags)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# embedding_out = [sentence length, batch size, embedding dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0membedding_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# char_emb_out = [batch size, sentence length, word length, char emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "sentence = 'The will deliver a speech about the conflict in Sao Paulo at tomorrow in Anne Mary with Jack.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                  TAG,\n",
    "                                  CHAR)\n",
    "\n",
    "print(unks)\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "k4LF_qyLKvfK"
   ],
   "name": "4 - Sequence Labeling with Conditional Random Field (CRF) as Output Layer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
