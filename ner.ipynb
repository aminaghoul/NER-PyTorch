{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/opt/conda/bin/python'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "{sys.executable}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f943c1a25f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports for this tutorial\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f  = open(\"test.txt\", \"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "data_test = []\n",
    "tag_test = []\n",
    "t = []\n",
    "sent = []\n",
    "label = []\n",
    "vocab = {}\n",
    "tag_map = {}\n",
    "for i, line in enumerate(f1):  \n",
    "    if line.split(): #on ne prend pas en compte les listes vides\n",
    "        vocab[line.split()[0]] = i\n",
    "        sent.append(line.split()[0])\n",
    "        \n",
    "        tag = [s for s in line.split()[1:] if s not in string.punctuation]\n",
    "        tag_test.append(tag[-1])\n",
    "        t.append(tag[-1])\n",
    "        \n",
    "    else:\n",
    "        if tag_test:\n",
    "            label.append(\" \".join(tag_test))\n",
    "            tag_test = []\n",
    "        if sent:\n",
    "            data_test.append(\" \".join(sent))\n",
    "            sent = []\n",
    "        \n",
    "for j, w in enumerate(t):\n",
    "    tag_map[w] = j       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = max(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.update(UNK = maxi+1, PAD = maxi+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []        \n",
    "train_labels = []\n",
    "\n",
    "for sentence in data_test:\n",
    "    s = [vocab[token] if token in vocab \n",
    "        else vocab['UNK']\n",
    "        for token in sentence.split(' ')]\n",
    "    train_sentences.append(s)\n",
    "\n",
    "for sentence in label:\n",
    "    #replace each label by its index\n",
    "    l = [tag_map[la] for la in sentence.split(' ')]\n",
    "    train_labels.append(l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisation du GPU si possible \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =[ [[50068, 50069, 732, 4, 5, 49476, 50345, 8, 49392, 41417, 11, 50347],\n",
    "  [14, 15],\n",
    "  [1331, 50345, 50311, 48188, 48189, 49192],\n",
    "     [12,84,6,4545,2111,5,8,9,45]],[[50068, 50069, 732, 4, 5, 49476, 50345, 8, 49392, 41417, 11, 50347], [14, 15]] ]\n",
    "print(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data_iterator(train_sentences, train_labels, batch_size = 64)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-458-b59c8b47232f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for i,j in train_iterator:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((71, 32, 1))\n",
    "# x.shape = torch.Size([71, 32, 1])\n",
    "px = torch.cat((torch.zeros(29, 32, 1, dtype=x.dtype, device=x.device), x), dim=0)\n",
    "# px.shape = torch.Size([100, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64 #batch size  \n",
    "# using list comprehension  \n",
    "batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "del batch_sentences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 64])\n",
      "torch.Size([18, 64])\n",
      "torch.Size([33, 64])\n",
      "torch.Size([124, 64])\n",
      "torch.Size([36, 64])\n"
     ]
    }
   ],
   "source": [
    "a, b = data_iterator(train_sentences, train_labels, batch_size = 64)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(train_sentences, train_labels, batch_size = 64):\n",
    "    n = batch_size\n",
    "    # création des batchs\n",
    "    batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "    del batch_sentences[-1] # on supprime le dernier batch car il est pas de longueur 64\n",
    "    \n",
    "    batch_tags = [train_labels[i:i + n] for i in range(0, len(train_labels), n)]    \n",
    "    del batch_tags[-1] \n",
    "    \n",
    "    batchs_data = []\n",
    "    batchs_labels = [] \n",
    "    \n",
    "    for i in range(len(batch_sentences)):\n",
    "        #compute length of longest sentence in batch\n",
    "        batch_max_len = max([len(s) for s in batch_sentences[i]])\n",
    "        #prepare a numpy array with the data, initializing the data with 'PAD' \n",
    "        #and all labels with -1; initializing labels to -1 differentiates tokens \n",
    "        #with tags from 'PAD' tokens\n",
    "        batch_data = vocab[\"PAD\"]*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "        batch_labels = -1*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "        #copy the data to the numpy array\n",
    "        for j in range(len(batch_sentences[i])):\n",
    "            cur_len = len(batch_sentences[i][j])\n",
    "            batch_data[j][:cur_len] = batch_sentences[i][j]\n",
    "            batch_labels[j][:cur_len] = batch_tags[i][j]\n",
    "            \n",
    "        batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels) \n",
    "        batch_data = batch_data.transpose(0, 1)\n",
    "        batch_labels = batch_labels.transpose(0, 1)\n",
    "        batchs_data.append(batch_data.squeeze(1))\n",
    "        batchs_labels.append(batch_labels.squeeze(1))\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    batchs_data = torch.cat(batchs_data,dim = 0)  \n",
    "    batchs_labels = torch.cat(batchs_labels, dim = 0)  \n",
    "    #since all data are indices, we convert them to torch LongTensors\n",
    "    batchs_data, batchs_labels = torch.LongTensor(batchs_data), torch.LongTensor(batchs_labels)\n",
    "    #convert Tensors to Variables\n",
    "    batchs_data, batchs_labels = Variable(batchs_data), Variable(batchs_labels)\n",
    "    print(batchs_data.shape)\n",
    "    print('l',batchs_labels.shape)\n",
    "    \"\"\"\n",
    "    return batchs_data, batchs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,bidirectional):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "               \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(tag_map)\n",
    "BIDIRECTIONAL = True\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,BIDIRECTIONAL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([72, 64])) must be the same as input size (torch.Size([64]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-488-3f0756ae5703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([72, 64])) must be the same as input size (torch.Size([64]))"
     ]
    }
   ],
   "source": [
    "n = 64\n",
    "# création des batchs\n",
    "batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "del batch_sentences[-1] # on supprime le dernier batch car il est pas de longueur 64\n",
    "    \n",
    "batch_tags = [train_labels[i:i + n] for i in range(0, len(train_labels), n)]    \n",
    "del batch_tags[-1] \n",
    "\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "model.train()\n",
    "        \n",
    "for i in range(len(batch_sentences)):\n",
    "    #compute length of longest sentence in batch\n",
    "    batch_max_len = max([len(s) for s in batch_sentences[i]])\n",
    "    #prepare a numpy array with the data, initializing the data with 'PAD' \n",
    "    #and all labels with -1; initializing labels to -1 differentiates tokens \n",
    "    #with tags from 'PAD' tokens\n",
    "    batch_data = vocab[\"PAD\"]*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "    batch_labels = -1*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "    #copy the data to the numpy array\n",
    "    for j in range(len(batch_sentences[i])):\n",
    "        cur_len = len(batch_sentences[i][j])\n",
    "        batch_data[j][:cur_len] = batch_sentences[i][j]\n",
    "        batch_labels[j][:cur_len] = batch_tags[i][j]\n",
    "            \n",
    "    batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels) \n",
    "    batch_data = batch_data.transpose(0, 1)\n",
    "    batch_labels = batch_labels.transpose(0, 1)\n",
    "\n",
    "    optimizer.zero_grad()    \n",
    "    text = batch_data.to(device)\n",
    "    predictions = model(text).squeeze(1)    \n",
    "    loss = criterion(predictions, batch_labels)    \n",
    "    acc = binary_accuracy(predictions, batch_labels)    \n",
    "    loss.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "        \n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -7132.589 | Train Acc: 4.52%\n",
      "\t Val. Loss: -12209.397 |  Val. Acc: 4.78%\n",
      "Epoch: 02 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -16873.896 | Train Acc: 4.55%\n",
      "\t Val. Loss: -21499.249 |  Val. Acc: 4.78%\n",
      "Epoch: 03 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -26063.534 | Train Acc: 4.52%\n",
      "\t Val. Loss: -30691.432 |  Val. Acc: 4.78%\n",
      "Epoch: 04 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -35041.484 | Train Acc: 4.55%\n",
      "\t Val. Loss: -39791.703 |  Val. Acc: 4.78%\n",
      "Epoch: 05 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -44442.868 | Train Acc: 4.52%\n",
      "\t Val. Loss: -48840.225 |  Val. Acc: 4.78%\n",
      "Epoch: 06 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -53533.904 | Train Acc: 4.50%\n",
      "\t Val. Loss: -57877.539 |  Val. Acc: 4.78%\n",
      "Epoch: 07 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -62506.677 | Train Acc: 4.50%\n",
      "\t Val. Loss: -66997.074 |  Val. Acc: 4.78%\n",
      "Epoch: 08 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -71536.145 | Train Acc: 4.57%\n",
      "\t Val. Loss: -75940.350 |  Val. Acc: 4.78%\n",
      "Epoch: 09 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -80561.081 | Train Acc: 4.50%\n",
      "\t Val. Loss: -85052.044 |  Val. Acc: 4.78%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: -89534.172 | Train Acc: 4.52%\n",
      "\t Val. Loss: -94024.795 |  Val. Acc: 4.78%\n"
     ]
    }
   ],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Retourne l'accuracy par batch\n",
    "    \"\"\"\n",
    "    #arrondi la prédiction à l'entier le plus proche\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'params' has no attribute 'vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-5df460f344ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-5df460f344ba>\u001b[0m in \u001b[0;36mNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#maps each token to an embedding_dim vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#the LSTM takens embedded sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'params' has no attribute 'vocab_size'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_dim, embedding_dim, hidden_dim, output_dim,bidirectional):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "    #maps each token to an embedding_dim vector\n",
    "    self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
    "\n",
    "    #the LSTM takens embedded sentence\n",
    "    self.lstm = nn.LSTM(params.embedding_dim, params.lstm_hidden_dim, batch_first=True)\n",
    "\n",
    "    #fc layer transforms the output to give the final output layer\n",
    "    self.fc = nn.Linear(params.lstm_hidden_dim, params.number_of_tags)\n",
    "    \n",
    "    def forward(self, s):\n",
    "        #apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "\n",
    "        #run the LSTM along the sentences of length batch_max_len\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
    "\n",
    "        #reshape the Variable so that each row contains one token\n",
    "        s = s.view(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
    "\n",
    "        #apply the fully connected layer and obtain the output for each token\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#train = pd.DataFrame({'text': train, 'label': label_train})\n",
    "test = pd.DataFrame({'text': train_sentences, 'label': train_labels})\n",
    "#valid = pd.DataFrame({'text': valid, 'label': label_valid})\n",
    "\n",
    "#train.to_csv (r'data/train.csv', index = False, header=True)\n",
    "test.to_csv (r'data_ner/test.csv', index = False, header=True)\n",
    "#valid.to_csv (r'data/valid.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données train: 3682\n",
      "Taille des données de validation: 3682\n",
      "Taille des données test: 3682\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#def generate_bigrams(x):\n",
    "#    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "#    for n_gram in n_grams:\n",
    "#        x.append(' '.join(n_gram))\n",
    "#    return x\n",
    "\n",
    "TEXT = data.Field(sequential=True,lower=True, tokenize = 'spacy', #preprocessing = generate_bigrams, \n",
    "                  include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path='./data_ner/', train='test.csv',\n",
    "        validation='test.csv', test='test.csv', format='csv', skip_header=True,\n",
    "        fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "print(f'Taille des données train: {len(train_data)}')\n",
    "print(f'Taille des données de validation: {len(valid_data)}')\n",
    "print(f'Taille des données test: {len(test_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
