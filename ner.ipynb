{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/opt/conda/bin/python'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "{sys.executable}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f943c1a25f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports for this tutorial\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f  = open(\"test.txt\", \"r\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "data_test = []\n",
    "tag_test = []\n",
    "t = []\n",
    "sent = []\n",
    "label = []\n",
    "vocab = {}\n",
    "tag_map = {}\n",
    "for i, line in enumerate(f1):  \n",
    "    if line.split(): #on ne prend pas en compte les listes vides\n",
    "        vocab[line.split()[0]] = i\n",
    "        sent.append(line.split()[0])\n",
    "        \n",
    "        tag = [s for s in line.split()[1:] if s not in string.punctuation]\n",
    "        tag_test.append(tag[-1])\n",
    "        t.append(tag[-1])\n",
    "        \n",
    "    else:\n",
    "        if tag_test:\n",
    "            label.append(\" \".join(tag_test))\n",
    "            tag_test = []\n",
    "        if sent:\n",
    "            data_test.append(\" \".join(sent))\n",
    "            sent = []\n",
    "        \n",
    "for j, w in enumerate(t):\n",
    "    tag_map[w] = j       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = max(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.update(UNK = maxi+1, PAD = maxi+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []        \n",
    "train_labels = []\n",
    "\n",
    "for sentence in data_test:\n",
    "    s = [vocab[token] if token in vocab \n",
    "        else vocab['UNK']\n",
    "        for token in sentence.split(' ')]\n",
    "    train_sentences.append(s)\n",
    "\n",
    "for sentence in label:\n",
    "    #replace each label by its index\n",
    "    l = [tag_map[la] for la in sentence.split(' ')]\n",
    "    train_labels.append(l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisation du GPU si possible \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =[ [[50068, 50069, 732, 4, 5, 49476, 50345, 8, 49392, 41417, 11, 50347],\n",
    "  [14, 15],\n",
    "  [1331, 50345, 50311, 48188, 48189, 49192],\n",
    "     [12,84,6,4545,2111,5,8,9,45]],[[50068, 50069, 732, 4, 5, 49476, 50345, 8, 49392, 41417, 11, 50347], [14, 15]] ]\n",
    "print(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data_iterator(train_sentences, train_labels, batch_size = 64)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-458-b59c8b47232f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for i,j in train_iterator:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((71, 32, 1))\n",
    "# x.shape = torch.Size([71, 32, 1])\n",
    "px = torch.cat((torch.zeros(29, 32, 1, dtype=x.dtype, device=x.device), x), dim=0)\n",
    "# px.shape = torch.Size([100, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 64 #batch size  \n",
    "# using list comprehension  \n",
    "batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "del batch_sentences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 64])\n",
      "torch.Size([18, 64])\n",
      "torch.Size([33, 64])\n",
      "torch.Size([124, 64])\n",
      "torch.Size([36, 64])\n"
     ]
    }
   ],
   "source": [
    "a, b = data_iterator(train_sentences, train_labels, batch_size = 64)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(train_sentences, train_labels, batch_size = 64):\n",
    "    n = batch_size\n",
    "    # cr√©ation des batchs\n",
    "    batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "    del batch_sentences[-1] # on supprime le dernier batch car il est pas de longueur 64\n",
    "    \n",
    "    batch_tags = [train_labels[i:i + n] for i in range(0, len(train_labels), n)]    \n",
    "    del batch_tags[-1] \n",
    "    \n",
    "    batchs_data = []\n",
    "    batchs_labels = [] \n",
    "    \n",
    "    for i in range(len(batch_sentences)):\n",
    "        #compute length of longest sentence in batch\n",
    "        batch_max_len = max([len(s) for s in batch_sentences[i]])\n",
    "        #prepare a numpy array with the data, initializing the data with 'PAD' \n",
    "        #and all labels with -1; initializing labels to -1 differentiates tokens \n",
    "        #with tags from 'PAD' tokens\n",
    "        batch_data = vocab[\"PAD\"]*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "        batch_labels = -1*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "        #copy the data to the numpy array\n",
    "        for j in range(len(batch_sentences[i])):\n",
    "            cur_len = len(batch_sentences[i][j])\n",
    "            batch_data[j][:cur_len] = batch_sentences[i][j]\n",
    "            batch_labels[j][:cur_len] = batch_tags[i][j]\n",
    "            \n",
    "        batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels) \n",
    "        batch_data = batch_data.transpose(0, 1)\n",
    "        batch_labels = batch_labels.transpose(0, 1)\n",
    "        batchs_data.append(batch_data.squeeze(1))\n",
    "        batchs_labels.append(batch_labels.squeeze(1))\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    batchs_data = torch.cat(batchs_data,dim = 0)  \n",
    "    batchs_labels = torch.cat(batchs_labels, dim = 0)  \n",
    "    #since all data are indices, we convert them to torch LongTensors\n",
    "    batchs_data, batchs_labels = torch.LongTensor(batchs_data), torch.LongTensor(batchs_labels)\n",
    "    #convert Tensors to Variables\n",
    "    batchs_data, batchs_labels = Variable(batchs_data), Variable(batchs_labels)\n",
    "    print(batchs_data.shape)\n",
    "    print('l',batchs_labels.shape)\n",
    "    \"\"\"\n",
    "    return batchs_data, batchs_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,bidirectional):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, bidirectional=bidirectional)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "               \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        \n",
    "        return self.fc(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(tag_map)\n",
    "BIDIRECTIONAL = True\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,BIDIRECTIONAL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([72, 64])) must be the same as input size (torch.Size([64]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-488-3f0756ae5703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([72, 64])) must be the same as input size (torch.Size([64]))"
     ]
    }
   ],
   "source": [
    "n = 64\n",
    "# cr√©ation des batchs\n",
    "batch_sentences = [train_sentences[i:i + n] for i in range(0, len(train_sentences), n)]\n",
    "del batch_sentences[-1] # on supprime le dernier batch car il est pas de longueur 64\n",
    "    \n",
    "batch_tags = [train_labels[i:i + n] for i in range(0, len(train_labels), n)]    \n",
    "del batch_tags[-1] \n",
    "\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "model.train()\n",
    "        \n",
    "for i in range(len(batch_sentences)):\n",
    "    #compute length of longest sentence in batch\n",
    "    batch_max_len = max([len(s) for s in batch_sentences[i]])\n",
    "    #prepare a numpy array with the data, initializing the data with 'PAD' \n",
    "    #and all labels with -1; initializing labels to -1 differentiates tokens \n",
    "    #with tags from 'PAD' tokens\n",
    "    batch_data = vocab[\"PAD\"]*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "    batch_labels = -1*np.ones((len(batch_sentences[i]), batch_max_len))\n",
    "    #copy the data to the numpy array\n",
    "    for j in range(len(batch_sentences[i])):\n",
    "        cur_len = len(batch_sentences[i][j])\n",
    "        batch_data[j][:cur_len] = batch_sentences[i][j]\n",
    "        batch_labels[j][:cur_len] = batch_tags[i][j]\n",
    "            \n",
    "    batch_data, batch_labels = torch.LongTensor(batch_data), torch.LongTensor(batch_labels) \n",
    "    batch_data = batch_data.transpose(0, 1)\n",
    "    batch_labels = batch_labels.transpose(0, 1)\n",
    "\n",
    "    optimizer.zero_grad()    \n",
    "    text = batch_data.to(device)\n",
    "    predictions = model(text).squeeze(1)    \n",
    "    loss = criterion(predictions, batch_labels)    \n",
    "    acc = binary_accuracy(predictions, batch_labels)    \n",
    "    loss.backward()\n",
    "        \n",
    "    optimizer.step()\n",
    "        \n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -7132.589 | Train Acc: 4.52%\n",
      "\t Val. Loss: -12209.397 |  Val. Acc: 4.78%\n",
      "Epoch: 02 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -16873.896 | Train Acc: 4.55%\n",
      "\t Val. Loss: -21499.249 |  Val. Acc: 4.78%\n",
      "Epoch: 03 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -26063.534 | Train Acc: 4.52%\n",
      "\t Val. Loss: -30691.432 |  Val. Acc: 4.78%\n",
      "Epoch: 04 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -35041.484 | Train Acc: 4.55%\n",
      "\t Val. Loss: -39791.703 |  Val. Acc: 4.78%\n",
      "Epoch: 05 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -44442.868 | Train Acc: 4.52%\n",
      "\t Val. Loss: -48840.225 |  Val. Acc: 4.78%\n",
      "Epoch: 06 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -53533.904 | Train Acc: 4.50%\n",
      "\t Val. Loss: -57877.539 |  Val. Acc: 4.78%\n",
      "Epoch: 07 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -62506.677 | Train Acc: 4.50%\n",
      "\t Val. Loss: -66997.074 |  Val. Acc: 4.78%\n",
      "Epoch: 08 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -71536.145 | Train Acc: 4.57%\n",
      "\t Val. Loss: -75940.350 |  Val. Acc: 4.78%\n",
      "Epoch: 09 | Epoch Time: 0m 1s\n",
      "\tTrain Loss: -80561.081 | Train Acc: 4.50%\n",
      "\t Val. Loss: -85052.044 |  Val. Acc: 4.78%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: -89534.172 | Train Acc: 4.52%\n",
      "\t Val. Loss: -94024.795 |  Val. Acc: 4.78%\n"
     ]
    }
   ],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Retourne l'accuracy par batch\n",
    "    \"\"\"\n",
    "    #arrondi la pr√©diction √† l'entier le plus proche\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'params' has no attribute 'vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-5df460f344ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-211-5df460f344ba>\u001b[0m in \u001b[0;36mNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#maps each token to an embedding_dim vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#the LSTM takens embedded sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'params' has no attribute 'vocab_size'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_dim, embedding_dim, hidden_dim, output_dim,bidirectional):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "    #maps each token to an embedding_dim vector\n",
    "    self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
    "\n",
    "    #the LSTM takens embedded sentence\n",
    "    self.lstm = nn.LSTM(params.embedding_dim, params.lstm_hidden_dim, batch_first=True)\n",
    "\n",
    "    #fc layer transforms the output to give the final output layer\n",
    "    self.fc = nn.Linear(params.lstm_hidden_dim, params.number_of_tags)\n",
    "    \n",
    "    def forward(self, s):\n",
    "        #apply the embedding layer that maps each token to its embedding\n",
    "        s = self.embedding(s)   # dim: batch_size x batch_max_len x embedding_dim\n",
    "\n",
    "        #run the LSTM along the sentences of length batch_max_len\n",
    "        s, _ = self.lstm(s)     # dim: batch_size x batch_max_len x lstm_hidden_dim                \n",
    "\n",
    "        #reshape the Variable so that each row contains one token\n",
    "        s = s.view(-1, s.shape[2])  # dim: batch_size*batch_max_len x lstm_hidden_dim\n",
    "\n",
    "        #apply the fully connected layer and obtain the output for each token\n",
    "        s = self.fc(s)          # dim: batch_size*batch_max_len x num_tags\n",
    "\n",
    "        return F.log_softmax(s, dim=1)   # dim: batch_size*batch_max_len x num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#train = pd.DataFrame({'text': train, 'label': label_train})\n",
    "test = pd.DataFrame({'text': train_sentences, 'label': train_labels})\n",
    "#valid = pd.DataFrame({'text': valid, 'label': label_valid})\n",
    "\n",
    "#train.to_csv (r'data/train.csv', index = False, header=True)\n",
    "test.to_csv (r'data_ner/test.csv', index = False, header=True)\n",
    "#valid.to_csv (r'data/valid.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des donn√©es train: 3682\n",
      "Taille des donn√©es de validation: 3682\n",
      "Taille des donn√©es test: 3682\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#def generate_bigrams(x):\n",
    "#    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
    "#    for n_gram in n_grams:\n",
    "#        x.append(' '.join(n_gram))\n",
    "#    return x\n",
    "\n",
    "TEXT = data.Field(sequential=True,lower=True, tokenize = 'spacy', #preprocessing = generate_bigrams, \n",
    "                  include_lengths=True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path='./data_ner/', train='test.csv',\n",
    "        validation='test.csv', test='test.csv', format='csv', skip_header=True,\n",
    "        fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "print(f'Taille des donn√©es train: {len(train_data)}')\n",
    "print(f'Taille des donn√©es de validation: {len(valid_data)}')\n",
    "print(f'Taille des donn√©es test: {len(test_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
