{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61u1pfXh2MyN"
   },
   "source": [
    "# LSTM et Attention\n",
    "\n",
    "\n",
    "Dans ce notebook, le but sera de faire de la reconnaissance d'entités nommées en utilisant le modèle d'attention associé au LSTM.\n",
    "\n",
    "L'attention est décrit dans l'article de [Vaswani et al., 2017](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf). \n",
    "\n",
    "Nous allons utiliser plusieurs couches d'attention à l'aide de la méthode de PyTorch `MultiheadAttention`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "ucl3Yfvyckdc",
    "outputId": "4cf6a69d-28e5-445c-ebbe-d0d40cb3f20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /home/amina/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (4.48.2)\n",
      "Requirement already satisfied: requests in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (2.22.0)\n",
      "Requirement already satisfied: torch in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.17.2)\n",
      "Requirement already satisfied: six in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (0.1.91)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (1.24.2)\n",
      "Requirement already satisfied: future in /home/amina/anaconda3/lib/python3.7/site-packages (from torch->torchtext==0.6.0) (0.17.1)\n",
      "Requirement already satisfied: pytorch-crf in /home/amina/anaconda3/lib/python3.7/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "!pip install pytorch-crf\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from torchcrf import CRF\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "from torchcrf import CRF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yePexcpdBni"
   },
   "source": [
    "# Préparer les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mH1o5Giyc-Cl"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 160000000 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-65abbd37263a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mmin_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMIN_FREQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.100d\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  unk_init = torch.Tensor.normal_)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             self.eos_token] + kwargs.pop('specials', [])\n\u001b[1;32m    308\u001b[0m             if tok is not None))\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    181\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading vectors from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mroot_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 160000000 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(lower = True) \n",
    "TAG = data.Field(unk_token = None) \n",
    "CHAR_NESTING= Field(tokenize=list)\n",
    "CHAR = NestedField(CHAR_NESTING) \n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path=\"data_ner/\",\n",
    "        train=\"train.csv\",\n",
    "        validation=\"valid.csv\",\n",
    "        test=\"test.csv\", format='csv', skip_header=True,\n",
    "        fields=(\n",
    "            ((\"text\", \"char\"), (TEXT, CHAR)), \n",
    "            (\"tag\", TAG)\n",
    "        )\n",
    "    )\n",
    "\n",
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "TAG.build_vocab(train_data)\n",
    "CHAR.build_vocab(train_data) \n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort=False)\n",
    "\n",
    "# padding index\n",
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "CHAR_PAD_IDX = CHAR.vocab.stoi[CHAR.pad_token]  \n",
    "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jH-cyyDAde-8"
   },
   "source": [
    "# Construire le modèle\n",
    "\n",
    "On ajoute une nouvelle couche à notre modèle. On utilise le module de PyTorch `MultiheadAttention`, qui est une implémentation du mécanisme d'attention décrit dans [cet article](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf). \n",
    "\n",
    "Les inputs (*query*, *key*, and *value*) pour la couche d'attention sont les mêmes : la sortie du LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tla69_ChdVwQ"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,\n",
    "                 char_input_dim,\n",
    "                 char_cnn_filter_num,\n",
    "                 char_cnn_kernel_size,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 lstm_layers,\n",
    "                 attn_heads,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,\n",
    "                 lstm_dropout,\n",
    "                 attn_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,  \n",
    "                 char_pad_idx,\n",
    "                 tag_pad_idx):\n",
    "        super().__init__()\n",
    "        self.char_pad_idx = char_pad_idx  \n",
    "        self.word_pad_idx = word_pad_idx  \n",
    "        self.tag_pad_idx = tag_pad_idx  \n",
    "        \n",
    "        # LAYER 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # LAYER 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim \n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "        \n",
    "        # LAYER 2: BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim + (char_emb_dim * char_cnn_filter_num),\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # LAYER 3: Self-attention\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim * 2,\n",
    "            num_heads=attn_heads,\n",
    "            dropout=attn_dropout\n",
    "        )\n",
    "        \n",
    "        # LAYER 4: Fully-connected\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) \n",
    "        \n",
    "        # LAYER 5: CRF\n",
    "        self.crf = CRF(num_tags=output_dim)\n",
    "        \n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars, tags=None):\n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # tags = [sentence length, batch size]\n",
    "        \n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "\n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels)\n",
    "        for sent_i in range(sent_len):\n",
    "            \n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]\n",
    "            \n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)\n",
    "            \n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "\n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2).to(device)\n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    "        \n",
    "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
    "        lstm_out, _ = self.lstm(word_features)\n",
    "        \n",
    "        # crée mask pour padding\n",
    "        # key_padding_mask = [batch size, sentence length]\n",
    "        key_padding_mask = torch.as_tensor(words == self.word_pad_idx).permute(1, 0)\n",
    "        \n",
    "        # attn_out = [sentence length, batch size, hidden dim * 2]\n",
    "        # attn_weight = [batch size, sentence length, sentence length]\n",
    "        attn_out, attn_weight = self.attn(lstm_out, lstm_out, lstm_out, key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        # fc_out = [sentence length, batch size, output dim]\n",
    "        fc_out = self.fc(self.fc_dropout(attn_out))\n",
    "        \n",
    "        crf_mask = words != self.word_pad_idx\n",
    "        crf_out = self.crf.decode(fc_out, mask=crf_mask)\n",
    "        crf_loss = -self.crf(fc_out, tags=tags, mask=crf_mask) if tags is not None else None\n",
    "        return crf_out, crf_loss, attn_weight\n",
    "\n",
    "    def init_embeddings(self, char_pad_idx, word_pad_idx, pretrained=None, freeze=True):\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n",
    "\n",
    "    def init_crf_transitions(self, tag_names, imp_value=-100):\n",
    "        \n",
    "        num_tags = len(tag_names)\n",
    "        for i in range(num_tags):\n",
    "            tag_name = tag_names[i]\n",
    "            \n",
    "            # I et <pad> impossible au début\n",
    "            if tag_name[0] in (\"I\") or tag_name == \"<pad>\":\n",
    "                torch.nn.init.constant_(self.crf.start_transitions[i], imp_value)\n",
    "                \n",
    "            # B impossible à la fin\n",
    "            #if tag_name[0] in (\"B\"):\n",
    "            #    torch.nn.init.constant_(self.crf.end_transitions[i], imp_value)\n",
    "                \n",
    "        # init transitions impossible entre positions\n",
    "        tag_is = {}\n",
    "        for tag_position in (\"B\", \"I\", \"O\"):\n",
    "            tag_is[tag_position] = [i for i, tag in enumerate(tag_names) if tag[0] == tag_position]\n",
    "        tag_is[\"P\"] = [i for i, tag in enumerate(tag_names) if tag == \"tag\"]\n",
    "        impossible_transitions_position = {\n",
    "            \"B\": \"BP\",\n",
    "            \"I\": \"BP\",\n",
    "            \"O\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_position.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        torch.nn.init.constant_(\n",
    "                            self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                        )\n",
    "        \n",
    "        # init transitions impossible pour I et B pour des entités de types différents\n",
    "        impossible_transitions_tags = {\n",
    "            \"B\": \"I\",\n",
    "            \"I\": \"I\"\n",
    "        }\n",
    "        for from_tag, to_tag_list in impossible_transitions_tags.items():\n",
    "            to_tags = list(to_tag_list)\n",
    "            for from_tag_i in tag_is[from_tag]:\n",
    "                for to_tag in to_tags:\n",
    "                    for to_tag_i in tag_is[to_tag]:\n",
    "                        if tag_names[from_tag_i].split(\"-\")[1] != tag_names[to_tag_i].split(\"-\")[1]:\n",
    "                            torch.nn.init.constant_(\n",
    "                                self.crf.transitions[from_tag_i, to_tag_i], imp_value\n",
    "                            )\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "cKUIfovfdj5c",
    "outputId": "25991bda-d650-48df-e4ca-b4080583e480"
   },
   "outputs": [],
   "source": [
    "model = BiLSTM(\n",
    "    input_dim=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(CHAR.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(TAG.vocab),\n",
    "    lstm_layers=2,\n",
    "    attn_heads=16,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    attn_dropout=0.25,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    tag_pad_idx=TAG_PAD_IDX\n",
    ")\n",
    "\n",
    "model.init_embeddings(\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    pretrained= TEXT.vocab.vectors,\n",
    "    freeze=True\n",
    ")\n",
    "# CRF transitions initialisation\n",
    "model.init_crf_transitions(\n",
    "    tag_names=TAG.vocab.itos\n",
    ")\n",
    "print(f\"Le modèle a {model.count_parameters():,} paramètres à entraîner.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8okYjPr3drvI"
   },
   "source": [
    "# Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "def f1_loss(preds, y):\n",
    "    index_o = TAG.vocab.stoi[\"O\"]\n",
    "    positive_labels = [i for i in range(len(TAG.vocab.itos))\n",
    "                           if i not in (TAG_PAD_IDX, index_o)]\n",
    "    flatten_preds = [pred for sent_pred in preds for pred in sent_pred]\n",
    "    positive_preds = [pred for pred in flatten_preds\n",
    "                          if pred not in (TAG_PAD_IDX, index_o)]\n",
    "    flatten_y = [tag for sent_tag in y for tag in sent_tag]\n",
    "    \n",
    "    f1 = f1_score(\n",
    "            y_true=flatten_y,\n",
    "            y_pred=flatten_preds,\n",
    "            labels=positive_labels,\n",
    "            average=\"micro\"\n",
    "        ) if len(positive_preds) > 0 else 0\n",
    "    \n",
    "    print(\"f1 : \", f1)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.tag\n",
    "        chars = batch.char \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_tags_list, batch_loss, _ = model(text, chars, tags)\n",
    "        \n",
    "        # pour calculer la loss et l'accuracy, on flatten true tags\n",
    "        true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "            ]\n",
    "        batch_acc = f1_loss(pred_tags_list, true_tags_list)\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_acc += batch_acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.tag\n",
    "            chars = batch.char\n",
    "            \n",
    "            pred_tags_list, batch_loss, _ = model(text, chars, tags)\n",
    "            true_tags_list = [\n",
    "                [tag for tag in sent_tag if tag != TAG_PAD_IDX]\n",
    "                for sent_tag in tags.permute(1, 0).tolist()\n",
    "                ]\n",
    "            batch_acc = f1_loss(pred_tags_list, true_tags_list)\n",
    "   \n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_acc += batch_acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut4-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut visualiser les poids d'attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attn(tokens, weights):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    im = ax.imshow(weights, cmap=plt.get_cmap(\"gray\"))\n",
    "    ax.set_xticks(list(range(len(tokens))))\n",
    "    ax.set_yticks(list(range(len(tokens))))\n",
    "    ax.set_xticklabels(tokens)\n",
    "    ax.set_yticklabels(tokens)\n",
    "    # Create colorbar\n",
    "    _ = ax.figure.colorbar(im, ax=ax)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def tag_sentence(model, device, sentence, text_field, tag_field, char_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    max_word_len = max([len(token) for token in tokens])\n",
    "    numericalized_chars = []\n",
    "    char_pad_id = char_field.vocab.stoi[CHAR.pad_token] \n",
    "    for token in tokens:\n",
    "        numericalized_chars.append(\n",
    "                [char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "                )\n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]  \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = torch.as_tensor(numericalized_chars)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device) \n",
    "    predictions, _, attn_weight = model(token_tensor, char_tensor)\n",
    "    visualize_attn(tokens, attn_weight.detach().cpu().numpy()[0])\n",
    "    predicted_tags = [tag_field.vocab.itos[t] for t in predictions[0]]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['tag']\n",
    "\n",
    "print(sentence)\n",
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       TAG,\n",
    "                                       CHAR)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The will deliver a speech about the conflict in Sao Paulo at tomorrow in Anne Mary with Jack.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                  TAG,\n",
    "                                  CHAR)\n",
    "\n",
    "print(unks)\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5 - BiLSTM with Multi-head Dot-Product Self-Attention for Indonesian NER",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
