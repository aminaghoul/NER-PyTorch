{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JClDF-ebiYLT"
   },
   "source": [
    "# Capture d'informations à partir des lettres majuscules avec l'embedding de caractères\n",
    "\n",
    "\n",
    "Une autre amélioration potentielle consiste à appliquer l'embedding de caractères. Une représentation d'embeddings de mots pré-entraînée, telle que word2vec, peut nécessiter de transformer les mots en minuscules. Pourtant, comme le font les humains, les lettres majuscules contiennent des informations utiles pour déterminer si un mot est une entité nommée ou non. Par conséquent, dans ce notebook, nous incluons l'embedding au niveau des caractères avec Convolutional Neural Network (CNN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "14tU5kWmq79z",
    "outputId": "67011ad1-1c38-4b88-8740-2bd1510bc3d7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6f281076c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "nFc-Ky0Wp7L7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fd64c78a-d0b9-4274-ca81-7993db590e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6.0 in /home/amina/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (4.48.2)\n",
      "Requirement already satisfied: requests in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (2.22.0)\n",
      "Requirement already satisfied: torch in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.5.0)\n",
      "Requirement already satisfied: numpy in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.17.2)\n",
      "Requirement already satisfied: six in /home/amina/anaconda3/lib/python3.7/site-packages (from torchtext==0.6.0) (1.12.0)\n",
      "Collecting sentencepiece (from torchtext==0.6.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/amina/anaconda3/lib/python3.7/site-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: future in /home/amina/anaconda3/lib/python3.7/site-packages (from torch->torchtext==0.6.0) (0.17.1)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchtext.data import Field, NestedField, BucketIterator\n",
    "from torchtext.datasets import SequenceTaggingDataset\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4rz26nAjq1z"
   },
   "source": [
    "## Préparer les données\n",
    "\n",
    "Torchtext fournit une classe pratique pour gérer une entrée basée sur des caractères appelée `NestedField`. Pour inclure les caractères en tant que `NestedField`, nous devons créer une sorte de conteneur ` char_nesting_field`, puis spécifier cet objet comme paramètre pour le `NestedField`. \n",
    "Pour la tokenisation, on utilise la fonction intégrée `list` pour transformer le mot en caractères. La fonction de tokenisation peut être spécifiée dans le conteneur `Field`. \n",
    "\n",
    "On construit également le vocabulaire pour le `char_field`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la reproductibilité\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower = True) \n",
    "TAG = data.Field(unk_token = None) # les tags sont tous connus on a alors unk_token = None\n",
    "CHAR_NESTING= Field(tokenize=list)\n",
    "CHAR = NestedField(CHAR_NESTING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "        path=\"data_ner/\",\n",
    "        train=\"train.csv\",\n",
    "        validation=\"valid.csv\",\n",
    "        test=\"test.csv\", format='csv', skip_header=True,\n",
    "        fields=(\n",
    "            ((\"text\", \"char\"), (TEXT, CHAR)), \n",
    "            (\"tag\", TAG)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 14986\n",
      "Number of validation examples: 3465\n",
      "Number of testing examples: 3683\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ, # les mots qui apparaissent moins que MIN_FREQ fois seront ignorés du vocabulaire\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "TAG.build_vocab(train_data)\n",
    "CHAR.build_vocab(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens dans le vocabulaire de TEXT vocabulary: 10952\n",
      "Unique tokens dans le vocabulaire de TAG : 10\n",
      "Unique tokens dans le vocabulaire de CHAR : 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens dans le vocabulaire de TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens dans le vocabulaire de TAG : {len(TAG.vocab)}\")\n",
    "print(f\"Unique tokens dans le vocabulaire de CHAR : {len(CHAR.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche un exemple : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'], 'char': [['E', 'U'], ['r', 'e', 'j', 'e', 'c', 't', 's'], ['G', 'e', 'r', 'm', 'a', 'n'], ['c', 'a', 'l', 'l'], ['t', 'o'], ['b', 'o', 'y', 'c', 'o', 't', 't'], ['B', 'r', 'i', 't', 'i', 's', 'h'], ['l', 'a', 'm', 'b'], ['.']], 'tag': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJtPUvimmxpv"
   },
   "source": [
    "# Construire le modèle\n",
    "\n",
    "Il y a deux nouvelles couches a ajouter basé sur le modèle de [Ma & Hovy (2016)](https://arxiv.org/abs/1603.01354):\n",
    "\n",
    "1. embedding de caractères\n",
    "2. CNN de l'embedding de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6hqBRQ3rZpY"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 char_emb_dim,  \n",
    "                 char_input_dim,  \n",
    "                 char_cnn_filter_num,  \n",
    "                 char_cnn_kernel_size, \n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 lstm_layers,\n",
    "                 emb_dropout,\n",
    "                 cnn_dropout,  \n",
    "                 lstm_dropout,\n",
    "                 fc_dropout,\n",
    "                 word_pad_idx,\n",
    "                 char_pad_idx):  \n",
    "        super().__init__()\n",
    "        \n",
    "        # Couche 1A: Word Embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout) \n",
    "        \n",
    "        # Couche 1B: Char Embedding-CNN\n",
    "        self.char_emb_dim = char_emb_dim\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=char_input_dim,\n",
    "            embedding_dim=char_emb_dim,\n",
    "            padding_idx=char_pad_idx\n",
    "        )\n",
    "        self.char_cnn = nn.Conv1d(\n",
    "            in_channels=char_emb_dim,\n",
    "            out_channels=char_emb_dim * char_cnn_filter_num,\n",
    "            kernel_size=char_cnn_kernel_size,\n",
    "            groups=char_emb_dim  # different 1d conv for each embedding dim\n",
    "        )\n",
    "        self.cnn_dropout = nn.Dropout(cnn_dropout)\n",
    "        \n",
    "        # Couche 2: BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size= embedding_dim + (char_emb_dim * char_cnn_filter_num),\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Couche 3: Fully-connected\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n",
    "        # init weights from normal distribution\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def forward(self, words, chars):\n",
    "        \n",
    "        # words = [sentence length, batch size]\n",
    "        # chars = [batch size, sentence length, word length)\n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(words))\n",
    "\n",
    "        # char_emb_out = [batch size, sentence length, word length, char emb dim]\n",
    "        char_emb_out = self.emb_dropout(self.char_emb(chars))\n",
    "        batch_size, sent_len, word_len, char_emb_dim = char_emb_out.shape\n",
    "        char_cnn_max_out = torch.zeros(batch_size, sent_len, self.char_cnn.out_channels)\n",
    "        \n",
    "        # pour l'embedding des caractères, on doit itérer sur les phrases       \n",
    "        for sent_i in range(sent_len):\n",
    "            # sent_char_emb = [batch size, word length, char emb dim]\n",
    "            sent_char_emb = char_emb_out[:, sent_i, :, :]  # get the character field of sent i\n",
    "            # sent_char_emb_p = [batch size, char emb dim, word length]\n",
    "            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)  # the channel (char emb dim) has to be the last dimension\n",
    "            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n",
    "            char_cnn_sent_out = self.char_cnn(sent_char_emb_p)\n",
    "            char_cnn_max_out[:, sent_i, :], _ = torch.max(char_cnn_sent_out, dim=2)  # max pooling over the word length dimension\n",
    "        char_cnn = self.cnn_dropout(char_cnn_max_out)\n",
    "\n",
    "        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n",
    "        char_cnn_p = char_cnn.permute(1, 0, 2).to(device)\n",
    "        word_features = torch.cat((embedding_out, char_cnn_p), dim=2)\n",
    "\n",
    "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
    "        lstm_out, _ = self.lstm(word_features)\n",
    "        # ner_out = [sentence length, batch size, output dim]\n",
    "        ner_out = self.fc(self.fc_dropout(lstm_out))\n",
    "        return ner_out\n",
    "\n",
    "    def init_embeddings(self, char_pad_idx, word_pad_idx, pretrained=None, freeze=True):\n",
    "        # initialise l'embedding pour les tokens pad à zéro\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "        self.char_emb.weight.data[char_pad_idx] = torch.zeros(self.char_emb_dim)\n",
    "        if pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embeddings=torch.as_tensor(pretrained),\n",
    "                padding_idx=word_pad_idx,\n",
    "                freeze=freeze\n",
    "            )\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare padding index to be ignored during model training/evaluation\n",
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "CHAR_PAD_IDX = CHAR.vocab.stoi[CHAR.pad_token]  \n",
    "TAG_PAD_IDX = TAG.vocab.stoi[TAG.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "F50qLmWTrwG7",
    "outputId": "095b951f-bc17-4faa-bef9-ec3e6dc875f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a 3,640,260 paramètres à entraîner.\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(10952, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (char_emb): Embedding(86, 25, padding_idx=1)\n",
      "  (char_cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n",
      "  (cnn_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(425, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (fc_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(\n",
    "    input_dim=len(TEXT.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(CHAR.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(TAG.vocab),\n",
    "    lstm_layers=2,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=TEXT_PAD_IDX,\n",
    "    char_pad_idx=CHAR_PAD_IDX\n",
    ")\n",
    "model.init_embeddings(\n",
    "    char_pad_idx=CHAR_PAD_IDX,\n",
    "    word_pad_idx=TEXT_PAD_IDX ,\n",
    "    freeze=True\n",
    ")\n",
    "print(f\"Le modèle a {model.count_parameters():,} paramètres à entraîner.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIb_h9XXreOv"
   },
   "source": [
    "# Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 61])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([42, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 42, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([58, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 58, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([67, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 67, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 23])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 23])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([58, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 58, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([113, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 113, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([59, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 59, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 60])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 52])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([39, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 39, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([59, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 59, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([60, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 60, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 32])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([78, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 78, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 34])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([39, 10])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([10, 39, 10])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([60, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 60, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 50])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([109, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 109, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([105, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 105, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([75, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 75, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 9])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([9, 44, 11])\n",
      "Epoch: 01 | Epoch Time: 6m 17s\n",
      "\tTrain Loss: 0.773 | Train Acc: 88.40%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 81.91%\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 60])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([59, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 59, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 17])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([60, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 60, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([58, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 58, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 23])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([58, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 58, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 23])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 21])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([59, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 59, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([67, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 67, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 32])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([113, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 113, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([78, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 78, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 34])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([42, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 42, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([57, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 57, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([60, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 60, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([42, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 42, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 50])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 61])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 25])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([39, 10])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([10, 39, 12])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 24])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 52])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([50, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 50, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 22])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([62, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 62, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 27])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([51, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 51, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([109, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 109, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([52, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 52, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([105, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 105, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 45, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([75, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 75, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([56, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 56, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 9])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([9, 44, 11])\n",
      "Epoch: 02 | Epoch Time: 6m 52s\n",
      "\tTrain Loss: 0.323 | Train Acc: 71.47%\n",
      "\t Val. Loss: 0.221 |  Val. Acc: 67.80%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "def f1_loss(preds, y, tag_pad_idx):\n",
    "    '''\n",
    "    Retourne le score F1\n",
    "    '''  \n",
    "     \n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) \n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    y_pred = (max_preds[non_pad_elements])\n",
    "    y_true = (y_pred == y[non_pad_elements]).float() \n",
    "            \n",
    "    tp = (y_true * y_pred).sum().float()\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().float()\n",
    "    fp = ((1 - y_true) * y_pred).sum().float()\n",
    "    fn = (y_true * (1 - y_pred)).sum().float()\n",
    "    \n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    if (tp + fn) == 0 or (tp + fp) == 0 or (recall + precision == 0):\n",
    "        f1 = torch.zeros(1)\n",
    "    else:\n",
    "        f1 = 2* (precision*recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.tag\n",
    "        chars = batch.char \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        predictions = model(text,chars)\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = f1_loss(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.tag\n",
    "            chars = batch.char\n",
    "            predictions = model(text,chars)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = f1_loss(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "N_EPOCHS = 2\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([72, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 72, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([124, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 124, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([44, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 44, 14])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([38, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 38, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([59, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 59, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([42, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 42, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([48, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 48, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([60, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 60, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 19])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([53, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 53, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([54, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 54, 17])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([39, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 39, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([69, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 69, 37])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([47, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 47, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([55, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 55, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([46, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 46, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([49, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 49, 18])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([37, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 37, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([41, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 41, 20])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([30, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 30, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([40, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 40, 16])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([16, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 16, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([43, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 43, 13])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([77, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 77, 15])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([16, 128])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([128, 16, 12])\n",
      "W torch.Size([10952, 300])\n",
      "I torch.Size([45, 99])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([99, 45, 13])\n",
      "Test Loss: 0.254 |  Test Acc: 66.73%\n"
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que l'accuracy est n'est pas beaucoup meilleure que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field, char_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    max_word_len = max([len(token) for token in tokens])\n",
    "    numericalized_chars = []\n",
    "    char_pad_id = char_field.vocab.stoi[CHAR.pad_token] \n",
    "    for token in tokens:\n",
    "        numericalized_chars.append(\n",
    "                [char_field.vocab.stoi[char] for char in token]\n",
    "                + [char_pad_id for _ in range(max_word_len - len(token))]\n",
    "                )\n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "    \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
    "    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = torch.as_tensor(numericalized_chars)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device) \n",
    "    \n",
    "    predictions = model(token_tensor, char_tensor)\n",
    "    \n",
    "    top_predictions = predictions.argmax(-1)\n",
    "    \n",
    "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['tag']\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([9, 1])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([1, 9, 7])\n",
      "['rejects']\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       TAG,\n",
    "                               \n",
    "                                       CHAR)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "B-ORG\t\tB-ORG\t\t✔\t\teu\n",
      "O\t\tO\t\t✔\t\trejects\n",
      "B-MISC\t\tB-MISC\t\t✔\t\tgerman\n",
      "O\t\tO\t\t✔\t\tcall\n",
      "O\t\tO\t\t✔\t\tto\n",
      "O\t\tO\t\t✔\t\tboycott\n",
      "B-MISC\t\tB-MISC\t\t✔\t\tbritish\n",
      "O\t\tO\t\t✔\t\tlamb\n",
      "O\t\tO\t\t✔\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([10952, 300])\n",
      "I torch.Size([21, 1])\n",
      "W torch.Size([86, 25])\n",
      "I torch.Size([1, 21, 8])\n",
      "['kate']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The will deliver a speech about the conflict in North Korea tomorrow in New York with my friend Mary Kate.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                  TAG,\n",
    "                                  CHAR)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "O\t\tthe\n",
      "O\t\twill\n",
      "O\t\tdeliver\n",
      "O\t\ta\n",
      "O\t\tspeech\n",
      "O\t\tabout\n",
      "O\t\tthe\n",
      "O\t\tconflict\n",
      "O\t\tin\n",
      "B-MISC\t\tnorth\n",
      "B-LOC\t\tkorea\n",
      "O\t\ttomorrow\n",
      "O\t\tin\n",
      "B-LOC\t\tnew\n",
      "B-LOC\t\tyork\n",
      "O\t\twith\n",
      "O\t\tmy\n",
      "O\t\tfriend\n",
      "B-PER\t\tmary\n",
      "I-PER\t\tkate\n",
      "O\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3 - Character-level embedding and CNN for Extra Features",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
